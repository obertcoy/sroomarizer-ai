{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import random\n",
    "from PyPDF2 import PdfReader\n",
    "import pandas as pd\n",
    "\n",
    "from spacy.pipeline import EntityRuler\n",
    "from spacy.lang.en import English\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jsonlines\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from typing import List\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturesExtractor:\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.nlp = spacy.load('./data/train_model/model_ner/')\n",
    "        \n",
    "        if \"sentencizer\" not in self.nlp.pipe_names:\n",
    "            self.nlp.add_pipe(\"sentencizer\")\n",
    "        \n",
    "        if 'entity_ruler' not in self.nlp.pipe_names:\n",
    "            ruler = self.nlp.add_pipe('entity_ruler', after='ner')\n",
    "            ruler.from_disk(constants.SKILLS_PATTERN_PATH)\n",
    "            \n",
    "            job_title_patterns = pd.read_csv(constants.JOB_TITLE_PATH)['Job Title'].unique()\n",
    "            \n",
    "            for title in job_title_patterns:\n",
    "                ruler.add_patterns([{\"label\": \"JOB TITLE\", \"pattern\": title}])\n",
    "        \n",
    "        self._CATEGORIES_PATTERN = constants.CATEGORIES_PATTERN\n",
    "    \n",
    "    def fit_transform(self, input: List[str]):\n",
    "        \n",
    "        self._text_arr = []\n",
    "        self._feature_arr = []\n",
    "        self._input_len = len(input)\n",
    "\n",
    "        for i in range(self._input_len):\n",
    "            \n",
    "            doc = self._remove_excess_spaces(input[i])\n",
    "            self._text_arr.append(doc.text)\n",
    "\n",
    "            self._extract_features(i, doc)\n",
    "\n",
    "        return self._text_arr, self._feature_arr\n",
    "\n",
    "    def _remove_excess_spaces(self, text):\n",
    "            \n",
    "        doc = self.nlp(re.sub(r'\\s+', ' ', text).strip())\n",
    "\n",
    "        return doc\n",
    "            \n",
    "\n",
    "    def _extract_features(self, resume_idx, doc):\n",
    "\n",
    "        feature_dict = {\n",
    "            \n",
    "            'resume_idx': resume_idx,\n",
    "            'name': self._extract_name(doc),\n",
    "            'phone': self._extract_phone(doc),\n",
    "            'educations': self._extract_educations(doc),\n",
    "            'gpa': self._extract_gpa(doc),\n",
    "            'job_titles' : self._extract_job_titles(doc),\n",
    "            'years_experiences': self._extract_years_experiences(doc),\n",
    "            'experiences': self._extract_experiences(doc),\n",
    "            'skills': self._extract_skills(doc),\n",
    "            'soft_skills': self._extract_soft_skills(doc),\n",
    "            'languages': self._extract_languages(doc),\n",
    "            \n",
    "        }\n",
    "        \n",
    "        self._feature_arr.append(feature_dict)\n",
    "           \n",
    "\n",
    "    def _extract_name(self, doc):\n",
    "        \n",
    "        name = []\n",
    "\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == 'PERSON':\n",
    "                name.append(ent.text)\n",
    "\n",
    "        return name\n",
    "\n",
    "\n",
    "    def _extract_phone(self, doc):\n",
    "\n",
    "        pattern = r'(?:\\+?(?:\\d{1,3}[-.\\s]?)?(?:\\(?\\d{2,4}\\)?[-.\\s]?)?(?:\\d{2,4}[-.\\s]?){2,5}\\d{2,4})'\n",
    "\n",
    "        matches = re.findall(pattern, doc.text)\n",
    "\n",
    "        return matches\n",
    "    \n",
    "    def _extract_educations(self, doc):\n",
    "        \n",
    "        educations = []\n",
    "\n",
    "        pattern = self._CATEGORIES_PATTERN['EDUCATIONS']\n",
    "        \n",
    "        matches = re.findall(pattern, doc.text)\n",
    "        for match in matches:\n",
    "            educations.append(match.strip())\n",
    "            \n",
    "        for ent in doc.ents:\n",
    "            if 'DIPLOMA' in ent.label_:\n",
    "                educations.append(ent.text)\n",
    "\n",
    "        return [edu for edu in set(educations)]\n",
    "    \n",
    "    def _extract_gpa(self, doc):\n",
    "        \n",
    "        gpas = []\n",
    "        \n",
    "        for ent in doc.ents:\n",
    "            if 'GPA' in ent.label_:\n",
    "                gpas.append(ent.text)\n",
    "                \n",
    "        return [gpa.capitalize() for gpa in set(gpas)]\n",
    "    \n",
    "    def _extract_job_titles(self, doc):\n",
    "        \n",
    "        job_titles = []\n",
    "        \n",
    "        for ent in doc.ents:\n",
    "            if 'JOB TITLE' in ent.label_:\n",
    "                job_titles.append(ent.text)\n",
    "        \n",
    "        return [job for job in set(job_titles)]\n",
    "    \n",
    "    def _extract_years_experiences(self, doc):\n",
    "        \n",
    "        years_experiences= []\n",
    "        \n",
    "        pattern = self._CATEGORIES_PATTERN['YEARS_EXPERIENCES']\n",
    "        \n",
    "        sentences = [sent.text.strip() for sent in doc.sents]\n",
    "\n",
    "        # for sentence in sentences:\n",
    "        #     if re.search(pattern, sentence, re.IGNORECASE):\n",
    "        #         years_experiences_sentences.append(sentence)\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            \n",
    "            matches = re.findall(pattern, sentence, re.IGNORECASE)\n",
    "                        \n",
    "            for match in matches:\n",
    "                \n",
    "                # Prevent context not parsed\n",
    "                try:\n",
    "\n",
    "                    \n",
    "                    year = match  # Extracted years\n",
    "                    year = re.sub(r'\\+', '', year)  # Remove '+' if present\n",
    "\n",
    "                    try:\n",
    "                        \n",
    "                        year = int(year)\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        \n",
    "                        print(f\"Error converting {match} to number: {e}\")\n",
    "                        continue\n",
    "\n",
    "                    match_doc = self.nlp(sentence)\n",
    "                    \n",
    "                    skills = self._extract_skills(match_doc)\n",
    "                    job_titles = self._extract_job_titles(match_doc)\n",
    "                    languages = self._extract_languages(match_doc)\n",
    "                    \n",
    "                    # Make string out of keywords for similarity scoring\n",
    "                    keywords_match = ' '.join(skills + languages)\n",
    "                    keywords_context = ' '.join(job_titles)\n",
    "\n",
    "                    years_experience_dict = {\n",
    "                        'text': sentence,\n",
    "                        'year': year,\n",
    "                        'keywords_match': keywords_match,\n",
    "                        'keywords_context': keywords_context\n",
    "                    }\n",
    "                    \n",
    "                    years_experiences.append(years_experience_dict)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing match {match}: {e}\")\n",
    "                    continue \n",
    "            \n",
    "        return years_experiences\n",
    "    \n",
    "    def _extract_experiences(self, doc):\n",
    "        \n",
    "        experiences = []\n",
    "        \n",
    "        pattern = self._CATEGORIES_PATTERN['EXPERIENCES']\n",
    "        \n",
    "        sentences = [sent.text.strip() for sent in doc.sents]\n",
    "\n",
    "        for sentence in sentences:\n",
    "            if re.search(pattern, sentence, re.IGNORECASE):\n",
    "                experiences.append(sentence)\n",
    "                \n",
    "        for ent in doc.ents:\n",
    "            if 'EXPERIENCE' in ent.label_:\n",
    "                experiences.append(ent.text)\n",
    "        \n",
    "        return [exp for exp in set(experiences)]\n",
    "    \n",
    "    def _extract_skills(self, doc):\n",
    "\n",
    "        skills = []\n",
    "\n",
    "        for ent in doc.ents:\n",
    "            if 'SKILL' in ent.label_ and 'SOFT SKILL' not in ent.label_:\n",
    "                skills.append(ent.text)\n",
    "                \n",
    "        return [skill.capitalize() for skill in set(skills)]\n",
    "    \n",
    "    def _extract_soft_skills(self, doc):\n",
    "        \n",
    "        soft_skills = []\n",
    "        \n",
    "        for ent in doc.ents:\n",
    "            if 'SOFT SKILL' in ent.label_:\n",
    "                soft_skills.append(ent.text)\n",
    "                \n",
    "        return [soft_skill for soft_skill in set(soft_skills)]\n",
    "\n",
    "    def _extract_languages(self, doc):\n",
    "        \n",
    "        languages = []\n",
    "\n",
    "        for ent in doc.ents:\n",
    "            if 'LANGUAGE' in ent.label_:\n",
    "                languages.append(ent.text)\n",
    "                \n",
    "        return [language.capitalize() for language in set(languages)]\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_parse(text):\n",
    "    \n",
    "    model = spacy.load('en_core_web_trf')\n",
    "    \n",
    "    print(model.pipe_names)\n",
    "\n",
    "    doc = model(text)\n",
    "    for ent in doc.ents:\n",
    "        print(f'{ent.label_.upper():{30}}- {ent.text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Anthonio Obert Software Developer+62 81273724892 laisobert2@gmail.com Jakarta, Indonesia SUMMARY A passionate college student with a keen interest in software development that is able to learn quickly and delve deeply into new subjects. Currently working as a Database Administrator for Bina Nusantara's Software Laboratory, where I manage and maintain student scores across multiple campuses with honesty and integrity. Capable of working under pressure and meeting deadlines. EXPERIENCE 02/2024 - Present Database Administrator Bina Nusantara University Manage and maintain student scores for laboratory subjects across six campuses: Kemanggisan, Alam Sutera, Bekasi, Bandung, Malang, and Semarang. Maintain web application to support internal and external activities. Create and maintain SQL query for internal and external requests. Provide student's scores data to identify and improve laboratory processes. Schedule important dates for laboratory activities. Post student's scores in Bina Nusantara University's internal application for students Process assistant's honor payment for case making and correction. 02/2023 - 02/2024 Laboratory Assistant Bina Nusantara University Teach hands-on programming classes (C, SQL, R, Python, Java, HTML, CSS, JS, etc). Created and graded student assignments, exams, and projects. Created and Passed Game Development (Unity, C#) for assistant's self-development project. Built a Desktop Application (Next.js, Electron, Typescript, Firebase, UML), Facebook Clone (React + Vite, Typescript, Go, GraphQL, PostgreSQL), Android Mobile Application (Kotlin, Firebase) for assistant's self-development project. EDUCATION 09/2022 - 09/2026 Computer Science Bina Nusantara University - Bachelor's Degree GPA: 3.82 IOFEST 2024 Web Development Finalist SKILLS Excel Intermediate Java Intermediate Python IntermediateSQL Advanced CSS Advanced Typescript Advanced 1 / 2LANGUAGES English Intermediate Bahasa Native 2 / 2\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PDF_PATH = './PDF/Anthonio Obert - Software Developer - CV (1).pdf'\n",
    "\n",
    "reader = PdfReader(PDF_PATH)\n",
    "n_pages = len(reader.pages)\n",
    "\n",
    "extracted_text = ''\n",
    "\n",
    "for i in range(n_pages):\n",
    "    page = reader.pages[i]\n",
    "    extracted_text += page.extract_text()\n",
    "\n",
    "extracted_text = re.sub(r'\\s+', ' ', extracted_text).strip()\n",
    "extracted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Educations:\n",
      "Bachelor's degree in Computer Science or equivalent\n",
      "\n",
      "GPA:\n",
      "  - No GPA information found\n",
      "\n",
      "Job Titles:\n",
      "Backend Software Engineer\n",
      "Software Engineer\n",
      "\n",
      "Years Experience:\n",
      "{'text': 'Having minimum 3 years of experience in software engineering (Java), application development or system development + experience in RDBMS and NoSQL databases.', 'year': 3, 'keywords_match': 'Nosql Java Software engineering Databases', 'keywords_context': ''}\n",
      "\n",
      "Experiences:\n",
      "Schedule important dates for laboratory activities. â€Ž Requirements Bachelor's degree in Computer Science or equivalent from a reputable university with good academic results is preferred.\n",
      "Strong object-oriented analysis and design skills.\n",
      "As a Backend Software Engineer, you are expected to: Be responsible for designing, building, improving, or maintaining our backend applications, third-party data integration, data API, backend systems, or working with monitoring tools and infrastructure Work in cross-functional teams and meet great people regularly from top tier technology, consulting, product, or academic background Be encouraged to speak your mind, propose ideas, influence others, and continuously grow yourself Participate and contribute to engineering hygiene such as code review, unit testing, and integration testing Participate and contribute to the solution and architectural design review.\n",
      "Experience in version control (Git/SVN/Mercurial) and familiarity with development collaboration tools\n",
      "Participate in the service support as on-call Participate and contribute to innovation and problem-solving Post student's scores in Bina Nusantara University's internal application for students Process assistant's honor payment for case making Schedule important dates for laboratory activities.\n",
      "Good business acumen, excellent problem skills and broad understanding of software and system design.\n",
      "Traveloka services related to new products, business models, business growth, market expansion and process optimization.\n",
      "Comfortable working up and down the technology stack.\n",
      "\n",
      "Skills:\n",
      "Bitbucket\n",
      "Databases\n",
      "Nosql\n",
      "Azure\n",
      "Phabricator\n",
      "Testing\n",
      "Software engineering\n",
      "Code review\n",
      "Java\n",
      "Jenkins\n",
      "Kubernetes\n",
      "Support\n",
      "System integration\n",
      "Engineering\n",
      "Teamcity\n",
      "Ansible\n",
      "Design\n",
      "Business process\n",
      "Data integration\n",
      "Software\n",
      "Monitoring tools\n",
      "Business\n",
      "Github\n",
      "Travis ci\n",
      "Api\n",
      "\n",
      "Skills:\n",
      "innovation\n",
      "effective, reliable and scalable solutions\n",
      "problem-solving\n",
      "excellent problem skills\n",
      "\n",
      "Languages:\n"
     ]
    }
   ],
   "source": [
    "PDF_PATH = './PDF/Anthonio Obert - Software Developer - CV (1).pdf'\n",
    "\n",
    "reader = PdfReader(PDF_PATH)\n",
    "n_pages = len(reader.pages)\n",
    "\n",
    "extracted_text = ''\n",
    "\n",
    "for i in range(n_pages):\n",
    "    page = reader.pages[i]\n",
    "    extracted_text += page.extract_text()\n",
    "\n",
    "extractor = FeaturesExtractor()\n",
    "\n",
    "texts, features = extractor.fit_transform([extracted_text])\n",
    "job_text, job_features = extractor.fit_transform([constants.DUMMY_JOB_DESCRIPTION])\n",
    "\n",
    "print(f'\\nEducations:')\n",
    "for education in job_features[0]['educations']:\n",
    "    print(education)\n",
    "    \n",
    "print(f'\\nGPA:')\n",
    "gpa = job_features[0]['gpa']\n",
    "if gpa:\n",
    "    for g in gpa:\n",
    "        print(f'  - {g}')\n",
    "else:\n",
    "    print('  - No GPA information found')\n",
    "\n",
    "print(f'\\nJob Titles:')\n",
    "for job_title in job_features[0]['job_titles']:\n",
    "    print(job_title)\n",
    "    \n",
    "print(f'\\nYears Experience:')\n",
    "for years_experience in job_features[0]['years_experiences']:\n",
    "    print(years_experience)\n",
    "\n",
    "print(f'\\nExperiences:')\n",
    "for experience in job_features[0]['experiences']:\n",
    "    print(experience)\n",
    "    \n",
    "print(f'\\nSkills:')\n",
    "for skill in job_features[0]['skills']:\n",
    "    print(skill)   \n",
    "    \n",
    "print(f'\\nSkills:')\n",
    "for soft_skill in job_features[0]['soft_skills']:\n",
    "    print(soft_skill)   \n",
    "    \n",
    "print(f'\\nLanguages:')\n",
    "for language in job_features[0]['languages']:\n",
    "    print(language)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Name:\n",
      "  - No name found\n",
      "\n",
      "Phone:\n",
      "  - +62 81273724892\n",
      "\n",
      "Educations:\n",
      "  - Bachelor's Degree GPA\n",
      "  - Bachelor's Degree GPA:\n",
      "\n",
      "GPA:\n",
      "  - 3.82\n",
      "\n",
      "Job Titles:\n",
      "  - Database Administrator\n",
      "\n",
      "Years Experience:\n",
      "  - No years experience found\n",
      "\n",
      "Experiences:\n",
      "  - Provide student's scores data to identify and improve laboratory processes.\n",
      "  - Currently working as a Database Administrator for Bina Nusantara's Software Laboratory, where I manage and maintain student scores across multiple campuses with honesty and integrity.\n",
      "  - Create and maintain SQL query for internal and external requests.\n",
      "  - EXPERIENCE 02/2024 - Present Database Administrator Bina Nusantara University Manage and maintain student scores for laboratory subjects across six campuses: Kemanggisan, Alam Sutera, Bekasi, Bandung, Malang, and Semarang.\n",
      "  - Post student's scores in Bina Nusantara University's internal application for students Process assistant's honor payment for case making\n",
      "  - Schedule important dates for laboratory activities.\n",
      "  - Maintain web application to support internal and external activities.\n",
      "  - Built a Desktop Application (Next.js, Electron, Typescript, Firebase, UML), Facebook Clone (React + Vite, Typescript, Go, GraphQL, PostgreSQL), Android Mobile Application (Kotlin, Firebase) for assistant's self-development project.\n",
      "\n",
      "Skills:\n",
      "  - Python\n",
      "  - Software\n",
      "  - Game development\n",
      "  - Java\n",
      "  - Unity\n",
      "  - Typescript\n",
      "  - C\n",
      "  - Support\n",
      "  - Css\n",
      "  - Computer science\n",
      "  - Software\n",
      "\n",
      "Soft Skills:\n",
      "  - Capable of working under pressure\n",
      "\n",
      "Languages:\n",
      "  - No languages found\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print all extracted features in a formatted way\n",
    "print(f'\\nName:')\n",
    "name = features[0]['name']\n",
    "if name:\n",
    "    print(f'  - {name[0]}')  # Assuming there is only one name\n",
    "else:\n",
    "    print('  - No name found')\n",
    "\n",
    "print(f'\\nPhone:')\n",
    "phone = features[0]['phone']\n",
    "if phone:\n",
    "    for p in phone:\n",
    "        print(f'  - {p}')\n",
    "else:\n",
    "    print('  - No phone number found')\n",
    "\n",
    "print(f'\\nEducations:')\n",
    "education = features[0]['educations']\n",
    "if education:\n",
    "    for edu in education:\n",
    "        print(f'  - {edu}')\n",
    "else:\n",
    "    print('  - No education information found')\n",
    "\n",
    "print(f'\\nGPA:')\n",
    "gpa = features[0]['gpa']\n",
    "if gpa:\n",
    "    for g in gpa:\n",
    "        print(f'  - {g}')\n",
    "else:\n",
    "    print('  - No GPA information found')\n",
    "    \n",
    "print(f'\\nJob Titles:')\n",
    "job_titles = features[0]['job_titles']\n",
    "if job_titles:\n",
    "    for job in job_titles:\n",
    "        print(f'  - {job}')\n",
    "else:\n",
    "    print('  - No job titles found')\n",
    "    \n",
    "    \n",
    "print(f'\\nYears Experience:')\n",
    "years_experiences = features[0]['years_experiences']\n",
    "if years_experiences:\n",
    "    for years in years_experiences:\n",
    "        print(f'  - {years}')\n",
    "else:\n",
    "    print('  - No years experience found')\n",
    "\n",
    "print(f'\\nExperiences:')\n",
    "experience = features[0]['experiences']\n",
    "if experience:\n",
    "    for exp in experience:\n",
    "        print(f'  - {exp}')\n",
    "else:\n",
    "    print('  - No experience information found')\n",
    "\n",
    "print(f'\\nSkills:')\n",
    "skills = features[0]['skills']\n",
    "if skills:\n",
    "    for skill in skills:\n",
    "        print(f'  - {skill}')\n",
    "else:\n",
    "    print('  - No skills found')\n",
    "\n",
    "print(f'\\nSoft Skills:')\n",
    "soft_skills = features[0]['soft_skills']\n",
    "if soft_skills:\n",
    "    for s_skill in soft_skills:\n",
    "        print(f'  - {s_skill}')\n",
    "else:\n",
    "    print('  - No soft skills found')\n",
    "\n",
    "print(f'\\nLanguages:')\n",
    "languages = features[0]['languages']\n",
    "if languages:\n",
    "    for language in languages:\n",
    "        print(f'  - {language}')\n",
    "else:\n",
    "    print('  - No languages found')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResumeRater:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self._pretrained_model = SentenceTransformer(constants.PRETRAINED_SENTENCE_TRANSFORMERS_MODEL)\n",
    "        \n",
    "        self._RATING_WEIGHTS = constants.RATING_WEIGHTS\n",
    "            \n",
    "    def fit_transform(self, job_description_text: List[str], resume_text: List[dict]):\n",
    "        \n",
    "        self._extractor = FeaturesExtractor()\n",
    "        \n",
    "        job_text, job_features = extractor.fit_transform(job_description_text)\n",
    "\n",
    "        # Only 1 job posting description\n",
    "        self._job_text = job_text[0] \n",
    "        self._job_features = job_features[0]\n",
    "        \n",
    "        self._resume_text, self._resume_features = extractor.fit_transform(resume_text)\n",
    "        \n",
    "        for feature in self._resume_features:\n",
    "        \n",
    "            feature['rating_details'] = {\n",
    "                \n",
    "                'educations': self._rate_educations(feature['educations']),\n",
    "                'gpa': self._rate_gpa(feature['gpa']),\n",
    "                'job_titles' : self._rate_job_titles(feature['job_titles']),\n",
    "                # 'years_experiences': self._rate_years_experiences(feature['years_experience']), TO BE UPDATED\n",
    "                'years_experiences': 0,\n",
    "                'experiences': self._rate_experiences(feature['experiences']),\n",
    "                'skills': self._rate_skills(feature['skills']),\n",
    "                'soft_skills': self._rate_soft_skills(feature['soft_skills']),\n",
    "                'languages': self._rate_languages(feature['languages']),\n",
    "                \n",
    "            }\n",
    "            \n",
    "            final_rating = 0\n",
    "            \n",
    "            for category, rating in feature['rating_details'].items():\n",
    "                \n",
    "                try:\n",
    "                    \n",
    "                    calculated_rating =  rating * self._RATING_WEIGHTS[str(category).upper()]\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    \n",
    "                    print(f'Error on parsing rating weights: {e}')\n",
    "                    continue\n",
    "                \n",
    "                final_rating += calculated_rating\n",
    "                 \n",
    "            feature['rating'] = final_rating\n",
    "            \n",
    "        \n",
    "        return self._resume_text, self._resume_features\n",
    "\n",
    "    def top_resume_by_rating(self, k = 5):\n",
    "            \n",
    "        sorted_resumes = sorted(self._resume_features, key=lambda x: x['rating'], reverse=True)\n",
    "    \n",
    "        top_k_resumes = sorted_resumes[:k]\n",
    "\n",
    "        return top_k_resumes\n",
    "            \n",
    "    def _calculate_cosine_similarity_matrix_mean(self, job_feature_category: List[str], resume_feature_category: List[str], use_threshold= False, threshold= 0.42):\n",
    "        \n",
    "        job_embeddings = self._pretrained_model.encode(job_feature_category)\n",
    "        resume_embeddings  = self._pretrained_model.encode(resume_feature_category)\n",
    "        \n",
    "        cosine_sim_matrix = util.pytorch_cos_sim(job_embeddings, resume_embeddings).numpy()\n",
    "        \n",
    "        top_similarity = cosine_sim_matrix.max(axis= 1) # Rows: Job, Columns: Resume -> Get max similarity per job\n",
    "        \n",
    "        score = top_similarity.mean()\n",
    "        \n",
    "        if use_threshold:\n",
    "\n",
    "            matches = np.sum(top_similarity >= threshold)\n",
    "                \n",
    "            # Calculate the score based on the number of matches and similarity >= threshold\n",
    "            if matches > 0:\n",
    "                score = (matches / len(job_text)) * np.mean(top_similarity[top_similarity >= threshold])\n",
    "            else:\n",
    "                score = 0.0\n",
    "                        \n",
    "        return float(score)\n",
    "\n",
    "    def _calculate_matching_words_score(self, job_word_list: List[str], resume_word_list: List[str]):\n",
    "        \n",
    "        n_job_word = len(job_word_list)\n",
    "        \n",
    "        if n_job_word <= 0:\n",
    "            return 1 # No extracted word on the category\n",
    "        \n",
    "        job_word_list = [word.lower() for word in job_word_list]\n",
    "        resume_word_list = [word.lower() for word in resume_word_list]\n",
    "        \n",
    "        score = 0\n",
    "        \n",
    "        for resume_word in resume_word_list:\n",
    "            \n",
    "            if resume_word in job_word_list:\n",
    "                score += 1\n",
    "\n",
    "        score /= n_job_word\n",
    "        \n",
    "        return score\n",
    "        \n",
    "    \n",
    "    def _rate_educations(self, resume_feature: List[str]):\n",
    "        \n",
    "        return self._calculate_cosine_similarity_matrix_mean(self._job_features['educations'], resume_feature)\n",
    "    \n",
    "    def _rate_gpa(self, resume_feature: List[str]):\n",
    "        \n",
    "        return 0\n",
    "    \n",
    "    def _rate_job_titles(self, resume_feature: List[str]):\n",
    "        \n",
    "        return self._calculate_cosine_similarity_matrix_mean(self._job_features['job_titles'], resume_feature, use_threshold=False)\n",
    "    \n",
    "    def _rate_years_experiences(self, resume_feature: List[str]):\n",
    "        \n",
    "        return self._calculate_cosine_similarity_matrix_mean(self._job_features['educations'], resume_feature)\n",
    "    \n",
    "    def _rate_experiences(self, resume_feature: List[str]):\n",
    "        \n",
    "        return self._calculate_cosine_similarity_matrix_mean(self._job_features['experiences'], resume_feature)\n",
    "        \n",
    "    def _rate_skills(self, resume_feature: List[str]):\n",
    "        \n",
    "        return self._calculate_matching_words_score(self._job_features['skills'], resume_feature)\n",
    "        \n",
    "    def _rate_soft_skills(self, resume_feature: List[str]):\n",
    "        \n",
    "        return self._calculate_cosine_similarity_matrix_mean(self._job_features['soft_skills'], resume_feature)\n",
    "        \n",
    "    def _rate_languages(self, resume_feature: List[str]):\n",
    "        \n",
    "        return self._calculate_matching_words_score(self._job_features['languages'], resume_feature)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Lomba\\ITFEST\\SROOMARIZER\\ai\\SROOMARIZER\\lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job: ['Backend Developer', 'Frontend Developer', 'Machine Learning Engineer', 'DevOps Engineer']\n",
      "Resume: ['Software engineering', 'Web Developer', 'Data Scientist', 'Data Analyst', 'Frontend Developer']\n",
      "['java spring sql'] ['java nosql databases']\n",
      "java nosql databases ['java spring sql']\n",
      "['java spring sql'] ['typescript javascript']\n",
      "typescript javascript ['java spring sql']\n",
      "['java spring sql'] ['python machine learning tensorflow']\n",
      "python machine learning tensorflow ['java spring sql']\n",
      "['java spring sql'] ['sql data analysis excel']\n",
      "sql data analysis excel ['java spring sql']\n",
      "['java spring sql'] ['html css react']\n",
      "html css react ['java spring sql']\n",
      "['javascript react css'] ['java nosql databases']\n",
      "java nosql databases ['javascript react css']\n",
      "['javascript react css'] ['typescript javascript']\n",
      "typescript javascript ['javascript react css']\n",
      "['javascript react css'] ['python machine learning tensorflow']\n",
      "python machine learning tensorflow ['javascript react css']\n",
      "['javascript react css'] ['sql data analysis excel']\n",
      "sql data analysis excel ['javascript react css']\n",
      "['javascript react css'] ['html css react']\n",
      "html css react ['javascript react css']\n",
      "['python machine learning nlp'] ['java nosql databases']\n",
      "java nosql databases ['python machine learning nlp']\n",
      "['python machine learning nlp'] ['typescript javascript']\n",
      "typescript javascript ['python machine learning nlp']\n",
      "['python machine learning nlp'] ['python machine learning tensorflow']\n",
      "python machine learning tensorflow ['python machine learning nlp']\n",
      "['python machine learning nlp'] ['sql data analysis excel']\n",
      "sql data analysis excel ['python machine learning nlp']\n",
      "['python machine learning nlp'] ['html css react']\n",
      "html css react ['python machine learning nlp']\n",
      "['aws docker kubernetes'] ['java nosql databases']\n",
      "java nosql databases ['aws docker kubernetes']\n",
      "['aws docker kubernetes'] ['typescript javascript']\n",
      "typescript javascript ['aws docker kubernetes']\n",
      "['aws docker kubernetes'] ['python machine learning tensorflow']\n",
      "python machine learning tensorflow ['aws docker kubernetes']\n",
      "['aws docker kubernetes'] ['sql data analysis excel']\n",
      "sql data analysis excel ['aws docker kubernetes']\n",
      "['aws docker kubernetes'] ['html css react']\n",
      "html css react ['aws docker kubernetes']\n",
      "match score: [[0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0]]\n",
      "top_similarity: [0.8823684  1.0000001  0.60785353 0.5873405 ]\n"
     ]
    }
   ],
   "source": [
    "test_resume_features = [\n",
    "    {\n",
    "        'year': 5,\n",
    "        'keywords_match': 'Java Nosql Databases',\n",
    "        'keywords_context': 'Software engineering'\n",
    "    },\n",
    "    {\n",
    "        'year': 3,\n",
    "        'keywords_match': 'Typescript Javascript',\n",
    "        'keywords_context': 'Web Developer'\n",
    "    },\n",
    "    {\n",
    "        'year': 8,\n",
    "        'keywords_match': 'Python Machine Learning TensorFlow',\n",
    "        'keywords_context': 'Data Scientist'\n",
    "    },\n",
    "    {\n",
    "        'year': 2,\n",
    "        'keywords_match': 'SQL Data Analysis Excel',\n",
    "        'keywords_context': 'Data Analyst'\n",
    "    },\n",
    "    {\n",
    "        'year': 4,\n",
    "        'keywords_match': 'HTML CSS React',\n",
    "        'keywords_context': 'Frontend Developer'\n",
    "    },\n",
    "]\n",
    "\n",
    "test_job_features = [\n",
    "    {\n",
    "        'year': 4,\n",
    "        'keywords_match': 'Java Spring SQL',\n",
    "        'keywords_context': 'Backend Developer'\n",
    "    },\n",
    "    {\n",
    "        'year': 2,\n",
    "        'keywords_match': 'JavaScript React CSS',\n",
    "        'keywords_context': 'Frontend Developer'\n",
    "    },\n",
    "    {\n",
    "        'year': 5,\n",
    "        'keywords_match': 'Python Machine Learning NLP',\n",
    "        'keywords_context': 'Machine Learning Engineer'\n",
    "    },\n",
    "    {\n",
    "        'year': 3,\n",
    "        'keywords_match': 'AWS Docker Kubernetes',\n",
    "        'keywords_context': 'DevOps Engineer'\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "def _calculate_cosine_similarity_matrix_mean(job_feature_category: List[str], resume_feature_category: List[str], row_weights: List[float] = None):\n",
    "    \n",
    "    n_job_word = len(job_feature_category)\n",
    "    \n",
    "    if n_job_word <= 0:\n",
    "        return 1\n",
    "    \n",
    "    print(f'Job: {job_feature_category}')\n",
    "    print(f'Resume: {resume_feature_category}')\n",
    "\n",
    "    \n",
    "    job_embeddings = model.encode(job_feature_category)\n",
    "    resume_embeddings  = model.encode(resume_feature_category)\n",
    "    \n",
    "    cosine_sim_matrix = util.pytorch_cos_sim(job_embeddings, resume_embeddings).numpy()\n",
    "    \n",
    "    if row_weights is not None:\n",
    "        \n",
    "        cosine_sim_matrix = cosine_sim_matrix * np.array(row_weights).reshape((-1, 1)) # Transform 1D to 2D with 1 data per columns\n",
    "    \n",
    "    top_similarity = cosine_sim_matrix.max(axis= 1) # Because job is in rows\n",
    "    \n",
    "    return cosine_sim_matrix, top_similarity , top_similarity.mean()\n",
    "\n",
    "\n",
    "def _calculate_matching_words_score(job_word_list: List[str], resume_word_list: List[str]):\n",
    "        \n",
    "    n_job_word = len(job_word_list)\n",
    "    \n",
    "    if n_job_word <= 0:\n",
    "        return 1 # No extracted word on the category\n",
    "    \n",
    "    job_word_list = [word.lower() for word in job_word_list]\n",
    "    resume_word_list = [word.lower() for word in resume_word_list]\n",
    "    \n",
    "    print(job_word_list, resume_word_list)\n",
    "    \n",
    "    score = 0\n",
    "    \n",
    "    for resume_word in resume_word_list:\n",
    "        print(resume_word, job_word_list)\n",
    "        if resume_word in job_word_list:\n",
    "            score += 1\n",
    "\n",
    "    score /= n_job_word\n",
    "    \n",
    "    return score\n",
    "        \n",
    "\n",
    "def _calculate_year_weight(job_year, resume_year):\n",
    "    \n",
    "    print(job_year, resume_year)\n",
    "    weight = min(job_year / resume_year, 1)\n",
    "    \n",
    "    \n",
    "    return weight\n",
    "\n",
    "    \n",
    "mtx, top_similarity, context_score = _calculate_cosine_similarity_matrix_mean([features['keywords_context'] for features in test_job_features], \n",
    "                                                                                [features['keywords_context'] for features in test_resume_features])\n",
    "\n",
    "match_score = []\n",
    "\n",
    "for job_keywords in test_job_features:\n",
    "    \n",
    "    score_per_job = []\n",
    "    \n",
    "    for resume_keywords in test_resume_features:\n",
    "        \n",
    "        score = _calculate_matching_words_score([job_keywords['keywords_match']], [resume_keywords['keywords_match']])\n",
    "        \n",
    "        score_per_job.append(score)\n",
    "        \n",
    "    match_score.append(score_per_job)\n",
    "    \n",
    "\n",
    "\n",
    "print(f'match score: {match_score}')\n",
    "print(f'top_similarity: {top_similarity}')\n",
    "\n",
    "\n",
    "# print((top_similarity * constants.YEARS_EXPERIENCE_KEYWORDS_WEIGHTS['KEYWORDS_CONTEXT']\n",
    "#       +\n",
    "#       match_score * constants.YEARS_EXPERIENCE_KEYWORDS_WEIGHTS['KEYWORDS_MATCH'])\n",
    "#       *\n",
    "#       _calculate_year_weight([features['year'] for features in test_job_features], \n",
    "#                                 [features['year'] for features in test_resume_features])\n",
    "#       )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2, 0.3]\n",
      "[[0.2]\n",
      " [0.3]]\n"
     ]
    }
   ],
   "source": [
    "test = [0.2, 0.3]\n",
    "\n",
    "print(test)\n",
    "\n",
    "print(np.array(test).reshape((-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5067527  0.17577899 0.28201088 0.42740208]\n",
      " [0.3362365  0.22355133 0.27252504 0.3434708 ]\n",
      " [0.23669623 0.10252491 0.18281116 0.29533428]\n",
      " [0.3382214  0.3504028  0.29262048 0.22224598]\n",
      " [0.2891426  0.19791049 0.21635374 0.54375005]]\n",
      "\n",
      "[0.5067527  0.3434708  0.29533428 0.3504028  0.54375005]\n",
      "\n",
      "0.40794215\n",
      "Resume score: 0.2101\n"
     ]
    }
   ],
   "source": [
    "job_text = ['C++', 'Embedded Systems', 'Firmware', 'IoT', 'Frontend engineer']\n",
    "resume_text = ['Java', 'Nosql', 'Databases', 'Software engineering']\n",
    "\n",
    "job = model.encode(job_text)\n",
    "resume = model.encode(resume_text)\n",
    "\n",
    "cosine_sim = util.pytorch_cos_sim(job, resume)\n",
    "\n",
    "job_len = len(job)\n",
    "\n",
    "cosine_sim_matrix = cosine_sim.numpy()\n",
    "print(cosine_sim_matrix)\n",
    "\n",
    "max_per_job = cosine_sim_matrix.max(axis=1)\n",
    "\n",
    "print()\n",
    "print(max_per_job)\n",
    "\n",
    "print()\n",
    "print(max_per_job.mean())\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "matches = np.sum(max_per_job >= threshold)\n",
    "    \n",
    "# Calculate the score based on the number of matches and their strengths\n",
    "if matches > 0:\n",
    "    score = (matches / len(job_text)) * np.mean(max_per_job[max_per_job >= threshold])\n",
    "else:\n",
    "    score = 0.0\n",
    "    \n",
    "print(f\"Resume score: {score:.4f}\")\n",
    "\n",
    "\n",
    "# rating = 0\n",
    "\n",
    "# if resume.lower() in job.lower():\n",
    "#     rating += 0.1\n",
    "    \n",
    "# print(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8246068  0.5252687  0.32776105 0.4130693  0.32009926]\n",
      " [0.46173808 0.3680032  0.29165304 0.32076508 0.30375063]\n",
      " [0.2843247  0.3277973  0.30289125 0.30853605 0.2963429 ]\n",
      " [0.3632027  0.4990375  0.45114562 0.35039157 0.30742115]]\n",
      "\n",
      "[0.8246068  0.46173808 0.3277973  0.4990375 ]\n",
      "\n",
      "0.5282949\n",
      "Resume score: 0.2062\n"
     ]
    }
   ],
   "source": [
    "job_text = ['Marketing Manager', 'Social Media Specialist', 'Content Creator', 'Software Engineer']\n",
    "resume_text = ['Marketing Supervisor', 'Project Manager', 'CAD Designer', 'Manufacturing Supervisor', 'Database Administrator']\n",
    "\n",
    "job = model.encode(job_text)\n",
    "resume = model.encode(resume_text)\n",
    "\n",
    "cosine_sim = util.pytorch_cos_sim(job, resume)\n",
    "\n",
    "job_len = len(job)\n",
    "\n",
    "cosine_sim_matrix = cosine_sim.numpy()\n",
    "print(cosine_sim_matrix)\n",
    "\n",
    "max_per_job = cosine_sim_matrix.max(axis=1)\n",
    "\n",
    "print()\n",
    "print(max_per_job)\n",
    "\n",
    "print()\n",
    "print(max_per_job.mean())\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "matches = np.sum(max_per_job >= threshold)\n",
    "    \n",
    "# Calculate the score based on the number of matches and their strengths\n",
    "if matches > 0:\n",
    "    score = (matches / len(job_text)) * np.mean(max_per_job[max_per_job >= threshold])\n",
    "else:\n",
    "    score = 0.0\n",
    "    \n",
    "print(f\"Resume score: {score:.4f}\")\n",
    "\n",
    "\n",
    "# rating = 0\n",
    "\n",
    "# if resume.lower() in job.lower():\n",
    "#     rating += 0.1\n",
    "    \n",
    "# print(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken using model.similarity: 0.026009082794189453\n",
      "Time taken using manual encoding + util.pytorch_cos_sim: 0.02451157569885254\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Load pre-trained model\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Define texts\n",
    "texts = [\n",
    "    \"Bachelor's Degree GPA\",\n",
    "    \"Bachelor's Degree GPAaaaaaaaaaaaaaaaaaaaa:\"\n",
    "]\n",
    "job_descriptions = [\n",
    "    \"Bachelor's degree in Computer Science or equivalent from a reputable university with good academic results is preferred\",\n",
    "    \"Bachelor's degree in Computer Science\"\n",
    "]\n",
    "\n",
    "# Benchmark model.similarity (if available)\n",
    "start_time = time.time()\n",
    "similarity_scores = model.similarity(model.encode(job_descriptions), model.encode(texts))  # Hypothetical function\n",
    "end_time = time.time()\n",
    "print(\"Time taken using model.similarity:\", end_time - start_time)\n",
    "\n",
    "# Benchmark manual encoding + util.pytorch_cos_sim\n",
    "start_time = time.time()\n",
    "resume_embeddings = model.encode(texts, convert_to_numpy=True)\n",
    "job_embeddings = model.encode(job_descriptions, convert_to_numpy=True)\n",
    "cosine_sim = util.pytorch_cos_sim(job_embeddings, resume_embeddings)\n",
    "end_time = time.time()\n",
    "print(\"Time taken using manual encoding + util.pytorch_cos_sim:\", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test test2 test3 test4'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1 = ['test', 'test2']\n",
    "list2 = ['test3']\n",
    "list3 = ['test4']\n",
    "\n",
    "final_list = list1 + list2 + list3\n",
    "\n",
    "' '.join(final_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_model = ResumeRater()\n",
    "\n",
    "resume_text, resume_features = rating_model.fit_transform([constants.DUMMY_JOB_DESCRIPTION], [extracted_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'resume_idx': 0,\n",
       "  'name': [],\n",
       "  'phone': ['+62 81273724892'],\n",
       "  'educations': [\"Bachelor's Degree GPA\", \"Bachelor's Degree GPA:\"],\n",
       "  'gpa': ['3.82'],\n",
       "  'job_titles': ['Database Administrator'],\n",
       "  'years_experiences': [],\n",
       "  'experiences': [\"Provide student's scores data to identify and improve laboratory processes.\",\n",
       "   \"Currently working as a Database Administrator for Bina Nusantara's Software Laboratory, where I manage and maintain student scores across multiple campuses with honesty and integrity.\",\n",
       "   'Create and maintain SQL query for internal and external requests.',\n",
       "   'EXPERIENCE 02/2024 - Present Database Administrator Bina Nusantara University Manage and maintain student scores for laboratory subjects across six campuses: Kemanggisan, Alam Sutera, Bekasi, Bandung, Malang, and Semarang.',\n",
       "   \"Post student's scores in Bina Nusantara University's internal application for students Process assistant's honor payment for case making\",\n",
       "   'Schedule important dates for laboratory activities.',\n",
       "   'Maintain web application to support internal and external activities.',\n",
       "   \"Built a Desktop Application (Next.js, Electron, Typescript, Firebase, UML), Facebook Clone (React + Vite, Typescript, Go, GraphQL, PostgreSQL), Android Mobile Application (Kotlin, Firebase) for assistant's self-development project.\"],\n",
       "  'skills': ['Python',\n",
       "   'Software',\n",
       "   'Game development',\n",
       "   'Java',\n",
       "   'Unity',\n",
       "   'Typescript',\n",
       "   'C',\n",
       "   'Support',\n",
       "   'Css',\n",
       "   'Computer science',\n",
       "   'Software'],\n",
       "  'soft_skills': ['Capable of working under pressure'],\n",
       "  'languages': [],\n",
       "  'rating_details': {'educations': 0.600299596786499,\n",
       "   'gpa': 0,\n",
       "   'job_titles': 0.32748937606811523,\n",
       "   'years_experiences': 0,\n",
       "   'experiences': 0.4563058614730835,\n",
       "   'skills': 0.16,\n",
       "   'soft_skills': 0.1865537315607071,\n",
       "   'languages': 1},\n",
       "  'rating': 0.36440614765882495}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_resume = rating_model.top_resume_by_rating()\n",
    "\n",
    "top_resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resume 1's Rating = 0.36, details:\n",
      "\n",
      " - Educations: 0.6003\n",
      " - Gpa: 0.0000\n",
      " - Job_titles: 0.3275\n",
      " - Years_experiences: 0.0000\n",
      " - Experiences: 0.4563\n",
      " - Skills: 0.1600\n",
      " - Soft_skills: 0.1866\n",
      " - Languages: 1.0000\n"
     ]
    }
   ],
   "source": [
    "for idx, resume in enumerate(resume_features):\n",
    "    \n",
    "    print(f\"\\nResume {idx + 1}'s Rating = {resume['rating']:.2f}, details:\\n\")\n",
    "    \n",
    "    for category, rating in resume['rating_details'].items():\n",
    "        \n",
    "        print(f' - {category.capitalize()}: {rating:.4f}')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SROOMARIZER",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
