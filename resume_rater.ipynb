{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import random\n",
    "from PyPDF2 import PdfReader\n",
    "import pandas as pd\n",
    "\n",
    "from spacy.pipeline import EntityRuler\n",
    "from spacy.lang.en import English\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jsonlines\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from typing import List\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturesExtractor:\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.nlp = spacy.load('./data/train_model/model_ner/')\n",
    "        \n",
    "        if \"sentencizer\" not in self.nlp.pipe_names:\n",
    "            self.nlp.add_pipe(\"sentencizer\")\n",
    "        \n",
    "        if 'entity_ruler' not in self.nlp.pipe_names:\n",
    "            ruler = self.nlp.add_pipe('entity_ruler', after='ner')\n",
    "            ruler.from_disk(constants.SKILLS_PATTERN_PATH)\n",
    "            \n",
    "            job_title_patterns = pd.read_csv(constants.JOB_TITLE_PATH)['Job Title'].unique()\n",
    "            \n",
    "            for title in job_title_patterns:\n",
    "                ruler.add_patterns([{\"label\": \"JOB TITLE\", \"pattern\": title}])\n",
    "        \n",
    "        self._CATEGORIES_PATTERN = constants.CATEGORIES_PATTERN\n",
    "    \n",
    "    def fit_transform(self, input: List[str]):\n",
    "        \n",
    "        self._text_arr = []\n",
    "        self._feature_arr = []\n",
    "        self._input_len = len(input)\n",
    "\n",
    "        for i in range(self._input_len):\n",
    "            \n",
    "            doc = self._remove_excess_spaces(input[i])\n",
    "            self._text_arr.append(doc.text)\n",
    "\n",
    "            self._extract_features(i, doc)\n",
    "\n",
    "        return self._text_arr, self._feature_arr\n",
    "\n",
    "    def _remove_excess_spaces(self, text):\n",
    "            \n",
    "        doc = self.nlp(re.sub(r'\\s+', ' ', text).strip())\n",
    "\n",
    "        return doc\n",
    "            \n",
    "\n",
    "    def _extract_features(self, resume_idx, doc):\n",
    "\n",
    "        feature_dict = {\n",
    "            \n",
    "            'resume_idx': resume_idx,\n",
    "            'name': self._extract_name(doc),\n",
    "            'phone': self._extract_phone(doc),\n",
    "            'educations': self._extract_educations(doc),\n",
    "            'gpa': self._extract_gpa(doc),\n",
    "            'job_titles' : self._extract_job_titles(doc),\n",
    "            'years_experiences': self._extract_years_experiences(doc),\n",
    "            'experiences': self._extract_experiences(doc),\n",
    "            'skills': self._extract_skills(doc),\n",
    "            'soft_skills': self._extract_soft_skills(doc),\n",
    "            'languages': self._extract_languages(doc),\n",
    "            \n",
    "        }\n",
    "        \n",
    "        self._feature_arr.append(feature_dict)\n",
    "           \n",
    "\n",
    "    def _extract_name(self, doc):\n",
    "        \n",
    "        name = []\n",
    "\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == 'PERSON':\n",
    "                name.append(ent.text)\n",
    "\n",
    "        return name\n",
    "\n",
    "\n",
    "    def _extract_phone(self, doc):\n",
    "\n",
    "        pattern = r'(?:\\+?(?:\\d{1,3}[-.\\s]?)?(?:\\(?\\d{2,4}\\)?[-.\\s]?)?(?:\\d{2,4}[-.\\s]?){2,5}\\d{2,4})'\n",
    "\n",
    "        matches = re.findall(pattern, doc.text)\n",
    "\n",
    "        return matches\n",
    "    \n",
    "    def _extract_educations(self, doc):\n",
    "        \n",
    "        educations = []\n",
    "\n",
    "        pattern = self._CATEGORIES_PATTERN['EDUCATIONS']\n",
    "        \n",
    "        matches = re.findall(pattern, doc.text)\n",
    "        for match in matches:\n",
    "            educations.append(match.strip())\n",
    "            \n",
    "        for ent in doc.ents:\n",
    "            if 'DIPLOMA' in ent.label_:\n",
    "                educations.append(ent.text)\n",
    "\n",
    "        return [edu for edu in set(educations)]\n",
    "    \n",
    "    def _extract_gpa(self, doc):\n",
    "        \n",
    "        gpas = []\n",
    "        \n",
    "        for ent in doc.ents:\n",
    "            if 'GPA' in ent.label_:\n",
    "                gpas.append(ent.text)\n",
    "                \n",
    "        return [gpa.capitalize() for gpa in set(gpas)]\n",
    "    \n",
    "    def _extract_job_titles(self, doc):\n",
    "        \n",
    "        job_titles = []\n",
    "        \n",
    "        for ent in doc.ents:\n",
    "            if 'JOB TITLE' in ent.label_:\n",
    "                job_titles.append(ent.text)\n",
    "        \n",
    "        return [job for job in set(job_titles)]\n",
    "    \n",
    "    def _extract_years_experiences(self, doc):\n",
    "        \n",
    "        years_experiences= []\n",
    "        \n",
    "        pattern = self._CATEGORIES_PATTERN['YEARS_EXPERIENCES']\n",
    "        \n",
    "        sentences = [sent.text.strip() for sent in doc.sents]\n",
    "\n",
    "        # for sentence in sentences:\n",
    "        #     if re.search(pattern, sentence, re.IGNORECASE):\n",
    "        #         years_experiences_sentences.append(sentence)\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            \n",
    "            matches = re.findall(pattern, sentence, re.IGNORECASE)\n",
    "                        \n",
    "            for match in matches:\n",
    "                \n",
    "                # Prevent context not parsed\n",
    "                try:\n",
    "\n",
    "                    \n",
    "                    year = match  # Extracted years\n",
    "                    year = re.sub(r'\\+', '', year)  # Remove '+' if present\n",
    "\n",
    "                    try:\n",
    "                        \n",
    "                        year = int(year)\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        \n",
    "                        print(f\"Error converting {match} to number: {e}\")\n",
    "                        continue\n",
    "\n",
    "                    match_doc = self.nlp(sentence)\n",
    "                    \n",
    "                    skills = self._extract_skills(match_doc)\n",
    "                    job_titles = self._extract_job_titles(match_doc)\n",
    "                    languages = self._extract_languages(match_doc)\n",
    "                    \n",
    "                    # Make list out of keywords for similarity scoring\n",
    "                    keywords_match = skills + languages\n",
    "                    keywords_context = job_titles\n",
    "                    \n",
    "                    if keywords_match or keywords_context:\n",
    "\n",
    "                        years_experience_dict = {\n",
    "                            'text': sentence,\n",
    "                            'year': year,\n",
    "                            'keywords_match': keywords_match,\n",
    "                            'keywords_context': keywords_context\n",
    "                        }\n",
    "                        \n",
    "                        years_experiences.append(years_experience_dict)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing match {match}: {e}\")\n",
    "                    continue \n",
    "            \n",
    "        return years_experiences\n",
    "    \n",
    "    def _extract_experiences(self, doc):\n",
    "        \n",
    "        experiences = []\n",
    "        \n",
    "        pattern = self._CATEGORIES_PATTERN['EXPERIENCES']\n",
    "        \n",
    "        sentences = [sent.text.strip() for sent in doc.sents]\n",
    "\n",
    "        for sentence in sentences:\n",
    "            if re.search(pattern, sentence, re.IGNORECASE):\n",
    "                experiences.append(sentence)\n",
    "                \n",
    "        for ent in doc.ents:\n",
    "            if 'EXPERIENCE' in ent.label_:\n",
    "                experiences.append(ent.text)\n",
    "        \n",
    "        return [exp for exp in set(experiences)]\n",
    "    \n",
    "    def _extract_skills(self, doc):\n",
    "\n",
    "        skills = []\n",
    "\n",
    "        for ent in doc.ents:\n",
    "            if 'SKILL' in ent.label_ and 'SOFT SKILL' not in ent.label_:\n",
    "                skills.append(ent.text)\n",
    "                \n",
    "        return [skill.capitalize() for skill in set(skills)]\n",
    "    \n",
    "    def _extract_soft_skills(self, doc):\n",
    "        \n",
    "        soft_skills = []\n",
    "        \n",
    "        for ent in doc.ents:\n",
    "            if 'SOFT SKILL' in ent.label_:\n",
    "                soft_skills.append(ent.text)\n",
    "                \n",
    "        return [soft_skill for soft_skill in set(soft_skills)]\n",
    "\n",
    "    def _extract_languages(self, doc):\n",
    "        \n",
    "        languages = []\n",
    "\n",
    "        for ent in doc.ents:\n",
    "            if 'LANGUAGE' in ent.label_:\n",
    "                languages.append(ent.text)\n",
    "                \n",
    "        return [language.capitalize() for language in set(languages)]\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_parse(text):\n",
    "    \n",
    "    model = spacy.load('en_core_web_trf')\n",
    "    \n",
    "    print(model.pipe_names)\n",
    "\n",
    "    doc = model(text)\n",
    "    for ent in doc.ents:\n",
    "        print(f'{ent.label_.upper():{30}}- {ent.text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Anthonio Obert Software Developer+62 81273724892 laisobert2@gmail.com Jakarta, Indonesia SUMMARY A passionate college student with a keen interest in software development that is able to learn quickly and delve deeply into new subjects. Currently working as a Database Administrator for Bina Nusantara's Software Laboratory, where I manage and maintain student scores across multiple campuses with honesty and integrity. Capable of working under pressure and meeting deadlines. EXPERIENCE 02/2024 - Present Database Administrator Bina Nusantara University Manage and maintain student scores for laboratory subjects across six campuses: Kemanggisan, Alam Sutera, Bekasi, Bandung, Malang, and Semarang. Maintain web application to support internal and external activities. Create and maintain SQL query for internal and external requests. Provide student's scores data to identify and improve laboratory processes. Schedule important dates for laboratory activities. Post student's scores in Bina Nusantara University's internal application for students Process assistant's honor payment for case making and correction. 02/2023 - 02/2024 Laboratory Assistant Bina Nusantara University Teach hands-on programming classes (C, SQL, R, Python, Java, HTML, CSS, JS, etc). Created and graded student assignments, exams, and projects. Created and Passed Game Development (Unity, C#) for assistant's self-development project. Built a Desktop Application (Next.js, Electron, Typescript, Firebase, UML), Facebook Clone (React + Vite, Typescript, Go, GraphQL, PostgreSQL), Android Mobile Application (Kotlin, Firebase) for assistant's self-development project. EDUCATION 09/2022 - 09/2026 Computer Science Bina Nusantara University - Bachelor's Degree GPA: 3.82 IOFEST 2024 Web Development Finalist SKILLS Excel Intermediate Java Intermediate Python IntermediateSQL Advanced CSS Advanced Typescript Advanced 1 / 2LANGUAGES English Intermediate Bahasa Native 2 / 2\""
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PDF_PATH = './PDF/Anthonio Obert - Software Developer - CV (1).pdf'\n",
    "\n",
    "reader = PdfReader(PDF_PATH)\n",
    "n_pages = len(reader.pages)\n",
    "\n",
    "extracted_text = ''\n",
    "\n",
    "for i in range(n_pages):\n",
    "    page = reader.pages[i]\n",
    "    extracted_text += page.extract_text()\n",
    "\n",
    "extracted_text = re.sub(r'\\s+', ' ', extracted_text).strip()\n",
    "extracted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Educations:\n",
      "Bachelor's degree in Computer Science or equivalent\n",
      "\n",
      "GPA:\n",
      "  - No GPA information found\n",
      "\n",
      "Job Titles:\n",
      "Backend Software Engineer\n",
      "Software Engineer\n",
      "\n",
      "Years Experience:\n",
      "{'text': 'Having minimum 3 years of experience in software engineering (Java), application development or system development + experience in RDBMS and NoSQL databases.', 'year': 3, 'keywords_match': ['Databases', 'Nosql', 'Java', 'Software engineering'], 'keywords_context': []}\n",
      "\n",
      "Experiences:\n",
      "Traveloka services related to new products, business models, business growth, market expansion and process optimization.\n",
      "Comfortable working up and down the technology stack.\n",
      "Good business acumen, excellent problem skills and broad understanding of software and system design.\n",
      "Schedule important dates for laboratory activities. ‎ Requirements Bachelor's degree in Computer Science or equivalent from a reputable university with good academic results is preferred.\n",
      "As a Backend Software Engineer, you are expected to: Be responsible for designing, building, improving, or maintaining our backend applications, third-party data integration, data API, backend systems, or working with monitoring tools and infrastructure Work in cross-functional teams and meet great people regularly from top tier technology, consulting, product, or academic background Be encouraged to speak your mind, propose ideas, influence others, and continuously grow yourself Participate and contribute to engineering hygiene such as code review, unit testing, and integration testing Participate and contribute to the solution and architectural design review.\n",
      "Participate in the service support as on-call Participate and contribute to innovation and problem-solving Post student's scores in Bina Nusantara University's internal application for students Process assistant's honor payment for case making Schedule important dates for laboratory activities.\n",
      "Strong object-oriented analysis and design skills.\n",
      "Experience in version control (Git/SVN/Mercurial) and familiarity with development collaboration tools\n",
      "\n",
      "Skills:\n",
      "Jenkins\n",
      "Travis ci\n",
      "Data integration\n",
      "Phabricator\n",
      "Kubernetes\n",
      "Code review\n",
      "Teamcity\n",
      "Nosql\n",
      "Software engineering\n",
      "Support\n",
      "Business\n",
      "Design\n",
      "Api\n",
      "Ansible\n",
      "Testing\n",
      "System integration\n",
      "Engineering\n",
      "Github\n",
      "Monitoring tools\n",
      "Bitbucket\n",
      "Software\n",
      "Java\n",
      "Azure\n",
      "Business process\n",
      "Databases\n",
      "\n",
      "Skills:\n",
      "excellent problem skills\n",
      "problem-solving\n",
      "effective, reliable and scalable solutions\n",
      "innovation\n",
      "\n",
      "Languages:\n"
     ]
    }
   ],
   "source": [
    "PDF_PATH = './PDF/Smith Resume.pdf'\n",
    "\n",
    "reader = PdfReader(PDF_PATH)\n",
    "n_pages = len(reader.pages)\n",
    "\n",
    "extracted_text = ''\n",
    "\n",
    "for i in range(n_pages):\n",
    "    page = reader.pages[i]\n",
    "    extracted_text += page.extract_text()\n",
    "\n",
    "extractor = FeaturesExtractor()\n",
    "\n",
    "texts, features = extractor.fit_transform([extracted_text])\n",
    "job_text, job_features = extractor.fit_transform([constants.DUMMY_JOB_DESCRIPTION])\n",
    "\n",
    "print(f'\\nEducations:')\n",
    "for education in job_features[0]['educations']:\n",
    "    print(education)\n",
    "    \n",
    "print(f'\\nGPA:')\n",
    "gpa = job_features[0]['gpa']\n",
    "if gpa:\n",
    "    for g in gpa:\n",
    "        print(f'  - {g}')\n",
    "else:\n",
    "    print('  - No GPA information found')\n",
    "\n",
    "print(f'\\nJob Titles:')\n",
    "for job_title in job_features[0]['job_titles']:\n",
    "    print(job_title)\n",
    "    \n",
    "print(f'\\nYears Experience:')\n",
    "for years_experience in job_features[0]['years_experiences']:\n",
    "    print(years_experience)\n",
    "\n",
    "print(f'\\nExperiences:')\n",
    "for experience in job_features[0]['experiences']:\n",
    "    print(experience)\n",
    "    \n",
    "print(f'\\nSkills:')\n",
    "for skill in job_features[0]['skills']:\n",
    "    print(skill)   \n",
    "    \n",
    "print(f'\\nSkills:')\n",
    "for soft_skill in job_features[0]['soft_skills']:\n",
    "    print(soft_skill)   \n",
    "    \n",
    "print(f'\\nLanguages:')\n",
    "for language in job_features[0]['languages']:\n",
    "    print(language)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Name:\n",
      "  - No name found\n",
      "\n",
      "Phone:\n",
      "  - 140749\n",
      "\n",
      "Educations:\n",
      "  - No education information found\n",
      "\n",
      "GPA:\n",
      "  - No GPA information found\n",
      "\n",
      "Job Titles:\n",
      "  - No job titles found\n",
      "\n",
      "Years Experience:\n",
      "  - {'text': 'Michael Smith BI / Big Data/ Azure Manchester , UK- Email me on Indeed: indeed.com/r/ falicent/140749dace5dc26f 10+ years of Experience in Designing, Development, Administration, Analysis, Management inthe Business Intelligence Da ta warehousing, Client Server Technologies, Web -based Applications, cloud solutions and Databases.', 'year': 10, 'keywords_match': ['Databases', 'Azure', 'Server', 'Business intelligence'], 'keywords_context': []}\n",
      "  - {'text': 'Less than 1 year) ADDITIONAL INFORMATION Professiona l Skills Excellent analytical, problem solving, communication, knowledge transfer and interpersonalskills with ability to interact with individuals at all the levels Quick learner and maintains cordial relationship with project manager and team members and good performer both in team and independent job environments Positive attitude towards superiors &amp; peers Supervised junior developers throughout project lifecycle and provided technical assistance.', 'year': 1, 'keywords_match': ['Amp'], 'keywords_context': []}\n",
      "\n",
      "Experiences:\n",
      "  - Performance tuning. Web API enha ncements.\n",
      "  - Microsoft Rewards members can earn points when searching with Bing, browsing with Microsoft Edge and making purchases at the Xbox Store\n",
      "  - Document dB stored procedures.\n",
      "  - Created big data scripts in cosmos C# data extractors\n",
      "  - Created stream analytics jobs to process event hub data\n",
      "  - Positive attitude towards superiors\n",
      "  - Supervised junior developers throughout project lifecycle and provided technical assistance.\n",
      "  - Willing to relocate: Anywhere WORK EXPERIENCE\n",
      "  - Document db• Web App API.\n",
      "  - Experience in database designing, scalability, back -up and recovery, writing andoptimizing SQL code and Stored Procedures, creating functions, views, triggers and indexes.\n",
      "  - End to end tracking Tool: Description: - This is real -time Tracking tool to track different business transactions like order, order response, functional acknowledgement, invoice flowing ins ide ICOE.\n",
      "  - Worked Azure data lake store/analytics for big data processing\n",
      "  - Microsoft Rewards members can earn points when searching with Bing, browsing with Microsoft Edge and making purchases at t he Xbox Store\n",
      "  - Data warehouse: Data analysis, star/ snow flake schema data modeling and design specific todata warehousing and business intelligence environment.\n",
      "  - End to end tracking tool stitches all the business transaction like order to cash flow and connects different hops inside ICOE like gateway, routing server, Proces sing server.\n",
      "  - Rewards live dashboards gives a live picture of usage world -wide and by markets like US, Canada, Australia, new user regis tration count, top/bottom performing rewards offers, orders stats and weekly trends of user activities, orders and new user registrations.\n",
      "  - Rewards data insights is data analytics\n",
      "  - Stream analytics job to transform data Power\n",
      "\n",
      "Skills:\n",
      "  - Analytics\n",
      "  - Database\n",
      "  - Data warehouse\n",
      "  - Server\n",
      "  - Web app\n",
      "  - Business intelligence\n",
      "  - Monitoring\n",
      "  - Windows\n",
      "  - Amp\n",
      "  - Angular\n",
      "  - Microsoft azure\n",
      "  - Access control\n",
      "  - Big data\n",
      "  - Big data\n",
      "  - Design\n",
      "  - Business\n",
      "  - Api\n",
      "  - Schedule\n",
      "  - Databases\n",
      "  - Web app\n",
      "  - Business intelligence\n",
      "  - Azure\n",
      "  - Data modeling\n",
      "  - Server\n",
      "  - Data analysis\n",
      "  - Sql\n",
      "  - Azure\n",
      "\n",
      "Soft Skills:\n",
      "  - problem solving\n",
      "  - Excellent analytical\n",
      "  - communication\n",
      "\n",
      "Languages:\n",
      "  - No languages found\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print all extracted features in a formatted way\n",
    "print(f'\\nName:')\n",
    "name = features[0]['name']\n",
    "if name:\n",
    "    print(f'  - {name[0]}')  # Assuming there is only one name\n",
    "else:\n",
    "    print('  - No name found')\n",
    "\n",
    "print(f'\\nPhone:')\n",
    "phone = features[0]['phone']\n",
    "if phone:\n",
    "    for p in phone:\n",
    "        print(f'  - {p}')\n",
    "else:\n",
    "    print('  - No phone number found')\n",
    "\n",
    "print(f'\\nEducations:')\n",
    "education = features[0]['educations']\n",
    "if education:\n",
    "    for edu in education:\n",
    "        print(f'  - {edu}')\n",
    "else:\n",
    "    print('  - No education information found')\n",
    "\n",
    "print(f'\\nGPA:')\n",
    "gpa = features[0]['gpa']\n",
    "if gpa:\n",
    "    for g in gpa:\n",
    "        print(f'  - {g}')\n",
    "else:\n",
    "    print('  - No GPA information found')\n",
    "    \n",
    "print(f'\\nJob Titles:')\n",
    "job_titles = features[0]['job_titles']\n",
    "if job_titles:\n",
    "    for job in job_titles:\n",
    "        print(f'  - {job}')\n",
    "else:\n",
    "    print('  - No job titles found')\n",
    "    \n",
    "    \n",
    "print(f'\\nYears Experience:')\n",
    "years_experiences = features[0]['years_experiences']\n",
    "if years_experiences:\n",
    "    for years in years_experiences:\n",
    "        print(f'  - {years}')\n",
    "else:\n",
    "    print('  - No years experience found')\n",
    "\n",
    "print(f'\\nExperiences:')\n",
    "experience = features[0]['experiences']\n",
    "if experience:\n",
    "    for exp in experience:\n",
    "        print(f'  - {exp}')\n",
    "else:\n",
    "    print('  - No experience information found')\n",
    "\n",
    "print(f'\\nSkills:')\n",
    "skills = features[0]['skills']\n",
    "if skills:\n",
    "    for skill in skills:\n",
    "        print(f'  - {skill}')\n",
    "else:\n",
    "    print('  - No skills found')\n",
    "\n",
    "print(f'\\nSoft Skills:')\n",
    "soft_skills = features[0]['soft_skills']\n",
    "if soft_skills:\n",
    "    for s_skill in soft_skills:\n",
    "        print(f'  - {s_skill}')\n",
    "else:\n",
    "    print('  - No soft skills found')\n",
    "\n",
    "print(f'\\nLanguages:')\n",
    "languages = features[0]['languages']\n",
    "if languages:\n",
    "    for language in languages:\n",
    "        print(f'  - {language}')\n",
    "else:\n",
    "    print('  - No languages found')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ResumeRater:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self._pretrained_model = SentenceTransformer(constants.PRETRAINED_SENTENCE_TRANSFORMERS_MODEL)\n",
    "        \n",
    "        self._RATING_WEIGHTS = constants.RATING_WEIGHTS\n",
    "        self._YEARS_EXPERIENCES_WEIGHTS = constants.YEARS_EXPERIENCES_WEIGHTS\n",
    "            \n",
    "    def fit_transform(self, job_description_text: List[str], resume_text: List[dict]):\n",
    "        \n",
    "        self._extractor = FeaturesExtractor()\n",
    "        \n",
    "        job_text, job_features = self._extractor.fit_transform(job_description_text)\n",
    "\n",
    "        # Only 1 job posting description\n",
    "        self._job_text = job_text[0] \n",
    "        self._job_features = job_features[0]\n",
    "        \n",
    "        self._resume_text, self._resume_features = self._extractor.fit_transform(resume_text)\n",
    "        \n",
    "        for feature in self._resume_features:\n",
    "        \n",
    "            feature['rating_details'] = {\n",
    "                \n",
    "                'educations': self._rate_educations(feature['educations']),\n",
    "                'gpa': self._rate_gpa(feature['gpa']),\n",
    "                'job_titles' : self._rate_job_titles(feature['job_titles']),\n",
    "                'years_experiences': self._rate_years_experiences(feature['years_experiences']),\n",
    "                'experiences': self._rate_experiences(feature['experiences']),\n",
    "                'skills': self._rate_skills(feature['skills']),\n",
    "                'soft_skills': self._rate_soft_skills(feature['soft_skills']),\n",
    "                'languages': self._rate_languages(feature['languages']),\n",
    "                \n",
    "            }\n",
    "            \n",
    "            final_rating = 0\n",
    "            \n",
    "            for category, rating in feature['rating_details'].items():\n",
    "                \n",
    "                try:\n",
    "                    \n",
    "                    calculated_rating =  rating * self._RATING_WEIGHTS[str(category).upper()]\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    \n",
    "                    print(f'Error on parsing rating weights: {e}')\n",
    "                    continue\n",
    "                \n",
    "                final_rating += calculated_rating\n",
    "                 \n",
    "            feature['rating'] = final_rating\n",
    "            \n",
    "        \n",
    "        return self._job_features, self._resume_features\n",
    "    \n",
    "    def top_resume_by_rating(self, k = 5):\n",
    "        \n",
    "        if k <= 0:\n",
    "            raise ValueError(f\"Parameter k must be non-negative and non-zero, got {k}.\")\n",
    "        \n",
    "        sorted_resumes = sorted(self._resume_features, key=lambda x: x['rating'], reverse=True)\n",
    "    \n",
    "        top_k_resumes = sorted_resumes[:k]\n",
    "\n",
    "        return top_k_resumes\n",
    "    \n",
    "    def _check_feature_availability(self, job_feature: List[str], resume_feature: List[str]):\n",
    "        \n",
    "        if len(job_feature) <= 0 or not job_feature:\n",
    "            return 1\n",
    "        \n",
    "        if len(resume_feature) <= 0 or not resume_feature:\n",
    "            return 0\n",
    "        \n",
    "        return -1\n",
    "    \n",
    "    def _calculate_cosine_similarity_matrix_mean(self, job_feature_category: List[str], resume_feature_category: List[str], return_matrix = False, use_threshold= False, threshold= 0.42):\n",
    "        \n",
    "        check_feature = self._check_feature_availability(job_feature_category, resume_feature_category)\n",
    "        \n",
    "        if check_feature != -1:\n",
    "            \n",
    "            m = len(job_feature_category)\n",
    "            n = len(resume_feature_category)\n",
    "            \n",
    "            return (check_feature, np.full((m, n), check_feature)) if return_matrix else check_feature\n",
    "        \n",
    "        job_embeddings = self._pretrained_model.encode(job_feature_category)\n",
    "        resume_embeddings  = self._pretrained_model.encode(resume_feature_category)\n",
    "        \n",
    "        cosine_sim_matrix = util.pytorch_cos_sim(job_embeddings, resume_embeddings).numpy()\n",
    "        \n",
    "        top_similarity = cosine_sim_matrix.max(axis= 1) # Rows: Job, Columns: Resume -> Get max similarity per job\n",
    "        \n",
    "        score = top_similarity.mean()\n",
    "        \n",
    "        if use_threshold:\n",
    "\n",
    "            matches = np.sum(top_similarity >= threshold)\n",
    "                \n",
    "            # Calculate the score based on the number of matches and similarity >= threshold\n",
    "            if matches > 0:\n",
    "                score = (matches / len(job_feature_category)) * np.mean(top_similarity[top_similarity >= threshold])\n",
    "            else:\n",
    "                score = 0.0\n",
    "                \n",
    "        if return_matrix:\n",
    "            return float(score), cosine_sim_matrix\n",
    "        \n",
    "        return float(score)\n",
    "\n",
    "    def _calculate_matching_words_score(self, job_word_list: List[str], resume_word_list: List[str]):\n",
    "                \n",
    "        check_feature = self._check_feature_availability(job_word_list, resume_word_list)\n",
    "        \n",
    "        if check_feature != -1:\n",
    "            return check_feature\n",
    "        \n",
    "        job_word_list = [word.lower() for word in job_word_list]\n",
    "        resume_word_list = [word.lower() for word in resume_word_list]\n",
    "        \n",
    "        score = 0\n",
    "        \n",
    "        for resume_word in resume_word_list:\n",
    "            \n",
    "            if resume_word in job_word_list:\n",
    "                score += 1\n",
    "\n",
    "        n_job_word = len(job_word_list)\n",
    "\n",
    "        score /= n_job_word\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    def _calculate_year_weight(self, job_year_list: List[int], resume_year_list: List[int]):\n",
    "        \n",
    "        check_feature = self._check_feature_availability(job_year_list, resume_year_list)\n",
    "        \n",
    "        if check_feature != -1:\n",
    "            return check_feature\n",
    "        \n",
    "        m = len(job_year_list)\n",
    "        n = len(resume_year_list)\n",
    "        \n",
    "        weight_mtx = np.zeros((m, n))\n",
    "        \n",
    "        for job_idx, job_year in enumerate(job_year_list):\n",
    "            \n",
    "            for resume_idx, resume_year in enumerate(resume_year_list):\n",
    "                \n",
    "                weight = min(resume_year / job_year, 1)\n",
    "                            \n",
    "                weight_mtx[job_idx, resume_idx] = weight\n",
    "        \n",
    "        return weight_mtx\n",
    "\n",
    "    \n",
    "    def _rate_educations(self, resume_feature: List[str]):\n",
    "        \n",
    "        return self._calculate_cosine_similarity_matrix_mean(self._job_features['educations'], resume_feature)\n",
    "    \n",
    "    def _rate_gpa(self, resume_feature: List[str]):\n",
    "        \n",
    "        return 0\n",
    "    \n",
    "    def _rate_job_titles(self, resume_feature: List[str]):\n",
    "        \n",
    "        return self._calculate_cosine_similarity_matrix_mean(self._job_features['job_titles'], resume_feature, use_threshold=False)\n",
    "    \n",
    "    def _rate_years_experiences(self, resume_feature: List[str]):\n",
    "                \n",
    "        job_keywords_context = [' '.join(features['keywords_context']) for features in self._job_features['years_experiences']]\n",
    "        resume_keywords_context = [' '.join(features['keywords_context']) for features in resume_feature]\n",
    "\n",
    "        if not job_keywords_context or job_keywords_context == ['']:\n",
    "            similarity_mtx = np.array([[1]])\n",
    "        elif not resume_keywords_context or job_keywords_context == ['']:\n",
    "            similarity_mtx = np.array([[0]])\n",
    "        else:\n",
    "            _, similarity_mtx = self._calculate_cosine_similarity_matrix_mean(job_keywords_context, resume_keywords_context, return_matrix= True)\n",
    "      \n",
    "        job_year_list = [features['year'] for features in self._job_features['years_experiences']]\n",
    "        resume_year_lsit = [features['year'] for features in resume_feature]\n",
    "        \n",
    "        year_weight_mtx = self._calculate_year_weight(job_year_list, resume_year_lsit)\n",
    "\n",
    "        job_keywords_match = [features['keywords_match'] for features in self._job_features['years_experiences']]\n",
    "        resume_keywords_match = [features['keywords_match'] for features in resume_feature]\n",
    "\n",
    "        \n",
    "        m = len(job_keywords_match)\n",
    "        n = len(resume_keywords_match)\n",
    "        \n",
    "        if m <= 0:\n",
    "            matching_mtx = np.array([[1]])\n",
    "        elif n <= 0:\n",
    "            matching_mtx = np.array([[0]])\n",
    "        else:\n",
    "            matching_mtx = np.zeros((m, n))\n",
    "\n",
    "            for job_idx, job_match in enumerate(job_keywords_match):\n",
    "                \n",
    "                for resume_idx, resume_match in enumerate(resume_keywords_match):\n",
    "                    \n",
    "                    matching_mtx[job_idx, resume_idx] = self._calculate_matching_words_score(job_match, resume_match)\n",
    "\n",
    "        \n",
    "        \n",
    "        weighted_similarity_mtx = similarity_mtx * self._YEARS_EXPERIENCES_WEIGHTS['KEYWORDS_CONTEXT']\n",
    "        weighted_matching_mtx = matching_mtx * self._YEARS_EXPERIENCES_WEIGHTS['KEYWORDS_MATCH']\n",
    "        \n",
    "        final_mtx = (weighted_similarity_mtx + weighted_matching_mtx) * year_weight_mtx\n",
    "        top_score = final_mtx.max(axis= 1)\n",
    "        score = top_score.mean()\n",
    "                \n",
    "        return score\n",
    "    \n",
    "    def _rate_experiences(self, resume_feature: List[str]):\n",
    "        \n",
    "        return self._calculate_cosine_similarity_matrix_mean(self._job_features['experiences'], resume_feature)\n",
    "        \n",
    "    def _rate_skills(self, resume_feature: List[str]):\n",
    "        \n",
    "        return self._calculate_matching_words_score(self._job_features['skills'], resume_feature)\n",
    "        \n",
    "    def _rate_soft_skills(self, resume_feature: List[str]):\n",
    "        \n",
    "        return self._calculate_cosine_similarity_matrix_mean(self._job_features['soft_skills'], resume_feature)\n",
    "        \n",
    "    def _rate_languages(self, resume_feature: List[str]):\n",
    "        \n",
    "        return self._calculate_matching_words_score(self._job_features['languages'], resume_feature)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Lomba\\ITFEST\\SROOMARIZER\\ai\\SROOMARIZER\\lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] [10, 1]\n",
      "['']\n",
      "[[1]] [[0.1625 0.    ]]\n",
      "[[0.5125     0.11666667]] [0.5125] 0.5125\n"
     ]
    }
   ],
   "source": [
    "rating_model = ResumeRater()\n",
    "\n",
    "resume_text, resume_features = rating_model.fit_transform([constants.DUMMY_JOB_DESCRIPTION], [extracted_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Lomba\\ITFEST\\SROOMARIZER\\ai\\SROOMARIZER\\lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.75       1.         0.5        1.        ]\n",
      " [1.         1.         1.         1.         1.        ]\n",
      " [1.         0.6        1.         0.4        0.8       ]\n",
      " [1.         1.         1.         0.66666667 1.        ]]\n",
      "Job: ['Backend Developer', 'Frontend Developer', 'Machine Learning Engineer', 'DevOps Engineer']\n",
      "Resume: ['Software engineering Front-end web developer', 'Web Developer', 'Data Scientist', 'Data Analyst', 'Frontend Developer']\n",
      "java ['java', 'spring', 'sql']\n",
      "nosql ['java', 'spring', 'sql']\n",
      "databases ['java', 'spring', 'sql']\n",
      "typescript ['java', 'spring', 'sql']\n",
      "javascript ['java', 'spring', 'sql']\n",
      "python ['java', 'spring', 'sql']\n",
      "machine ['java', 'spring', 'sql']\n",
      "learning ['java', 'spring', 'sql']\n",
      "tensorflow ['java', 'spring', 'sql']\n",
      "sql ['java', 'spring', 'sql']\n",
      "data ['java', 'spring', 'sql']\n",
      "analysis ['java', 'spring', 'sql']\n",
      "excel ['java', 'spring', 'sql']\n",
      "html ['java', 'spring', 'sql']\n",
      "css ['java', 'spring', 'sql']\n",
      "react ['java', 'spring', 'sql']\n",
      "java ['javascript', 'react', 'css']\n",
      "nosql ['javascript', 'react', 'css']\n",
      "databases ['javascript', 'react', 'css']\n",
      "typescript ['javascript', 'react', 'css']\n",
      "javascript ['javascript', 'react', 'css']\n",
      "python ['javascript', 'react', 'css']\n",
      "machine ['javascript', 'react', 'css']\n",
      "learning ['javascript', 'react', 'css']\n",
      "tensorflow ['javascript', 'react', 'css']\n",
      "sql ['javascript', 'react', 'css']\n",
      "data ['javascript', 'react', 'css']\n",
      "analysis ['javascript', 'react', 'css']\n",
      "excel ['javascript', 'react', 'css']\n",
      "html ['javascript', 'react', 'css']\n",
      "css ['javascript', 'react', 'css']\n",
      "react ['javascript', 'react', 'css']\n",
      "java ['python', 'machine', 'learning', 'nlp']\n",
      "nosql ['python', 'machine', 'learning', 'nlp']\n",
      "databases ['python', 'machine', 'learning', 'nlp']\n",
      "typescript ['python', 'machine', 'learning', 'nlp']\n",
      "javascript ['python', 'machine', 'learning', 'nlp']\n",
      "python ['python', 'machine', 'learning', 'nlp']\n",
      "machine ['python', 'machine', 'learning', 'nlp']\n",
      "learning ['python', 'machine', 'learning', 'nlp']\n",
      "tensorflow ['python', 'machine', 'learning', 'nlp']\n",
      "sql ['python', 'machine', 'learning', 'nlp']\n",
      "data ['python', 'machine', 'learning', 'nlp']\n",
      "analysis ['python', 'machine', 'learning', 'nlp']\n",
      "excel ['python', 'machine', 'learning', 'nlp']\n",
      "html ['python', 'machine', 'learning', 'nlp']\n",
      "css ['python', 'machine', 'learning', 'nlp']\n",
      "react ['python', 'machine', 'learning', 'nlp']\n",
      "java ['aws', 'docker', 'kubernetes']\n",
      "nosql ['aws', 'docker', 'kubernetes']\n",
      "databases ['aws', 'docker', 'kubernetes']\n",
      "typescript ['aws', 'docker', 'kubernetes']\n",
      "javascript ['aws', 'docker', 'kubernetes']\n",
      "python ['aws', 'docker', 'kubernetes']\n",
      "machine ['aws', 'docker', 'kubernetes']\n",
      "learning ['aws', 'docker', 'kubernetes']\n",
      "tensorflow ['aws', 'docker', 'kubernetes']\n",
      "sql ['aws', 'docker', 'kubernetes']\n",
      "data ['aws', 'docker', 'kubernetes']\n",
      "analysis ['aws', 'docker', 'kubernetes']\n",
      "excel ['aws', 'docker', 'kubernetes']\n",
      "html ['aws', 'docker', 'kubernetes']\n",
      "css ['aws', 'docker', 'kubernetes']\n",
      "react ['aws', 'docker', 'kubernetes']\n",
      "Final matrix: \n",
      "[[0.46019347 0.16639554 0.10696674 0.1503145  0.30882892]\n",
      " [0.27756426 0.44877966 0.09198597 0.07404397 0.78333333]\n",
      " [0.15306468 0.09902911 0.70024874 0.07746324 0.09381059]\n",
      " [0.18770118 0.20556918 0.14325257 0.07257955 0.17785232]]\n",
      "\n",
      "Max per row:[0.46019347 0.78333333 0.70024874 0.20556918]\n",
      "Final RESULT:0.5373361773788929\n"
     ]
    }
   ],
   "source": [
    "test_resume_features = [\n",
    "    {\n",
    "        'year': 5,\n",
    "        'keywords_match': ['Java', 'Nosql', 'Databases'],\n",
    "        'keywords_context': ['Software engineering', 'Front-end web developer']\n",
    "    },\n",
    "    {\n",
    "        'year': 3,\n",
    "        'keywords_match': ['Typescript', 'Javascript'],\n",
    "        'keywords_context': ['Web Developer']\n",
    "    },\n",
    "    {\n",
    "        'year': 8,\n",
    "        'keywords_match': ['Python', 'Machine', 'Learning', 'TensorFlow'],\n",
    "        'keywords_context': ['Data Scientist']\n",
    "    },\n",
    "    {\n",
    "        'year': 2,\n",
    "        'keywords_match': ['SQL', 'Data', 'Analysis', 'Excel'],\n",
    "        'keywords_context': ['Data Analyst']\n",
    "    },\n",
    "    {\n",
    "        'year': 4,\n",
    "        'keywords_match': ['HTML', 'CSS', 'React'],\n",
    "        'keywords_context': ['Frontend Developer']\n",
    "    },\n",
    "]\n",
    "\n",
    "test_job_features = [\n",
    "    {\n",
    "        'year': 4,\n",
    "        'keywords_match': ['Java', 'Spring', 'SQL'],\n",
    "        'keywords_context': ['Backend Developer']\n",
    "    },\n",
    "    {\n",
    "        'year': 2,\n",
    "        'keywords_match': ['JavaScript', 'React', 'CSS'],\n",
    "        'keywords_context': ['Frontend Developer']\n",
    "    },\n",
    "    {\n",
    "        'year': 5,\n",
    "        'keywords_match': ['Python', 'Machine', 'Learning', 'NLP'],\n",
    "        'keywords_context': ['Machine Learning Engineer']\n",
    "    },\n",
    "    {\n",
    "        'year': 3,\n",
    "        'keywords_match': ['AWS', 'Docker', 'Kubernetes'],\n",
    "        'keywords_context': ['DevOps Engineer']\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "def _calculate_cosine_similarity_matrix_mean(job_feature_category: List[str], resume_feature_category: List[str]):\n",
    "    \n",
    "    n_job_word = len(job_feature_category)\n",
    "    \n",
    "    if n_job_word <= 0:\n",
    "        return 1\n",
    "    \n",
    "    print(f'Job: {job_feature_category}')\n",
    "    print(f'Resume: {resume_feature_category}')\n",
    "\n",
    "    \n",
    "    job_embeddings = model.encode(job_feature_category)\n",
    "    resume_embeddings  = model.encode(resume_feature_category)\n",
    "    \n",
    "    cosine_sim_matrix = util.pytorch_cos_sim(job_embeddings, resume_embeddings).numpy()\n",
    "    \n",
    "    top_similarity = cosine_sim_matrix.max(axis= 1) # Because job is in rows\n",
    "    \n",
    "    return cosine_sim_matrix, top_similarity , top_similarity.mean()\n",
    "\n",
    "\n",
    "def _calculate_matching_words_score(job_word_list: List[str], resume_word_list: List[str]):\n",
    "        \n",
    "    n_job_word = len(job_word_list)\n",
    "    \n",
    "    if n_job_word <= 0:\n",
    "        return 1 # No extracted word on the category\n",
    "    \n",
    "    job_word_list = [word.lower() for word in job_word_list]\n",
    "    resume_word_list = [word.lower() for word in resume_word_list]\n",
    "        \n",
    "    score = 0\n",
    "    \n",
    "    for resume_word in resume_word_list:\n",
    "        print(resume_word, job_word_list)\n",
    "        if resume_word in job_word_list:\n",
    "            score += 1\n",
    "\n",
    "    score /= n_job_word\n",
    "    \n",
    "    return score\n",
    "        \n",
    "\n",
    "def _calculate_year_weight(job_year_list: List[int], resume_year_list: List[int]):\n",
    "        \n",
    "    m = len(job_year_list)\n",
    "    n = len(resume_year_list)\n",
    "    \n",
    "    weight_mtx = np.zeros((m, n))\n",
    "    \n",
    "    for job_idx, job_year in enumerate(job_year_list):\n",
    "        \n",
    "        for resume_idx, resume_year in enumerate(resume_year_list):\n",
    "            \n",
    "            weight = min(resume_year / job_year, 1)\n",
    "                        \n",
    "            weight_mtx[job_idx, resume_idx] = weight\n",
    "    \n",
    "    \n",
    "    return weight_mtx\n",
    "\n",
    "job_keywords_context = [' '.join(features['keywords_context']) for features in test_job_features]\n",
    "resume_keywords_context = [' '.join(features['keywords_context']) for features in test_resume_features]\n",
    "job_year_list = [features['year'] for features in test_job_features]\n",
    "resume_year_lsit = [features['year'] for features in test_resume_features]\n",
    "\n",
    "year_weight_mtx = _calculate_year_weight(job_year_list, resume_year_lsit)\n",
    "\n",
    "print(_calculate_year_weight([features['year'] for features in test_job_features],\n",
    "                             [features['year'] for features in test_resume_features]))\n",
    "\n",
    "similarity_mtx, top_similarity, context_score = _calculate_cosine_similarity_matrix_mean(job_keywords_context, \n",
    "                                                                                resume_keywords_context)\n",
    "job_keywords_match = [features['keywords_match'] for features in test_job_features]\n",
    "resume_keywords_match = [features['keywords_match'] for features in test_resume_features]\n",
    "\n",
    "m = len(job_keywords_match)\n",
    "n = len(resume_keywords_match)\n",
    "\n",
    "matching_mtx = np.zeros((m, n))\n",
    "\n",
    "for job_idx, job_match in enumerate(job_keywords_match):\n",
    "    \n",
    "    for resume_idx, resume_match in enumerate(resume_keywords_match):\n",
    "        \n",
    "        matching_mtx[job_idx, resume_idx] = _calculate_matching_words_score(job_match, resume_match)\n",
    "\n",
    "\n",
    "weighted_similarity_mtx = similarity_mtx * constants.YEARS_EXPERIENCES_WEIGHTS['KEYWORDS_CONTEXT']\n",
    "weighted_matching_mtx = matching_mtx * constants.YEARS_EXPERIENCES_WEIGHTS['KEYWORDS_MATCH']\n",
    "\n",
    "years_experiences_mtx = (weighted_similarity_mtx + weighted_matching_mtx) * year_weight_mtx\n",
    "print(f'Final matrix: \\n{years_experiences_mtx}\\n')\n",
    "\n",
    "        \n",
    "# Join many strings together for each keywords_context\n",
    "\n",
    "# print(job_feature_category)\n",
    "# print(resume_feature_category)\n",
    "\n",
    "# job_embeddings = model.encode(job_feature_category)\n",
    "# resume_embeddings  = model.encode(resume_feature_category)\n",
    "\n",
    "# cosine_sim_matrix = util.pytorch_cos_sim(job_embeddings, resume_embeddings).numpy()\n",
    "\n",
    "# print(job_embeddings, resume_embeddings, cosine_sim_matrix)\n",
    "\n",
    "# match_score = []\n",
    "\n",
    "# for job_keywords in test_job_features:\n",
    "    \n",
    "#     score_per_job = []\n",
    "    \n",
    "#     for resume_keywords in test_resume_features:\n",
    "        \n",
    "#         score = _calculate_matching_words_score([job_keywords['keywords_match']], [resume_keywords['keywords_match']])\n",
    "        \n",
    "#         score_per_job.append(score)\n",
    "        \n",
    "#     match_score.append(score_per_job)\n",
    "    \n",
    "\n",
    "\n",
    "# print(f'match score: {match_score}')\n",
    "print(f'Max per row:{years_experiences_mtx.max(axis= 1)}')\n",
    "print(f'Final RESULT:{years_experiences_mtx.max(axis= 1).mean()}')\n",
    "\n",
    "\n",
    "# print((top_similarity * constants.YEARS_EXPERIENCE_KEYWORDS_WEIGHTS['KEYWORDS_CONTEXT']\n",
    "#       +\n",
    "#       match_score * constants.YEARS_EXPERIENCE_KEYWORDS_WEIGHTS['KEYWORDS_MATCH'])\n",
    "#       *\n",
    "#       _calculate_year_weight([features['year'] for features in test_job_features], \n",
    "#                                 [features['year'] for features in test_resume_features])\n",
    "#       )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] [10, 1]\n",
      "['']\n",
      "[[1]] [[0.1625 0.    ]]\n",
      "[[0.5125     0.11666667]] [0.5125] 0.5125\n"
     ]
    }
   ],
   "source": [
    "rating_model = ResumeRater()\n",
    "\n",
    "resume_text, resume_features = rating_model.fit_transform([constants.DUMMY_JOB_DESCRIPTION], [extracted_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'resume_idx': 0,\n",
       "  'name': [],\n",
       "  'phone': ['140749'],\n",
       "  'educations': [],\n",
       "  'gpa': [],\n",
       "  'job_titles': [],\n",
       "  'years_experiences': [{'text': 'Michael Smith BI / Big Data/ Azure Manchester , UK- Email me on Indeed: indeed.com/r/ falicent/140749dace5dc26f 10+ years of Experience in Designing, Development, Administration, Analysis, Management inthe Business Intelligence Da ta warehousing, Client Server Technologies, Web -based Applications, cloud solutions and Databases.',\n",
       "    'year': 10,\n",
       "    'keywords_match': ['Databases',\n",
       "     'Azure',\n",
       "     'Server',\n",
       "     'Business intelligence'],\n",
       "    'keywords_context': []},\n",
       "   {'text': 'Less than 1 year) ADDITIONAL INFORMATION Professiona l Skills Excellent analytical, problem solving, communication, knowledge transfer and interpersonalskills with ability to interact with individuals at all the levels Quick learner and maintains cordial relationship with project manager and team members and good performer both in team and independent job environments Positive attitude towards superiors &amp; peers Supervised junior developers throughout project lifecycle and provided technical assistance.',\n",
       "    'year': 1,\n",
       "    'keywords_match': ['Amp'],\n",
       "    'keywords_context': []}],\n",
       "  'experiences': ['Performance tuning. Web API enha ncements.',\n",
       "   'Microsoft Rewards members can earn points when searching with Bing, browsing with Microsoft Edge and making purchases at the Xbox Store',\n",
       "   'Document dB stored procedures.',\n",
       "   'Created big data scripts in cosmos C# data extractors',\n",
       "   'Created stream analytics jobs to process event hub data',\n",
       "   'Positive attitude towards superiors',\n",
       "   'Supervised junior developers throughout project lifecycle and provided technical assistance.',\n",
       "   'Willing to relocate: Anywhere WORK EXPERIENCE',\n",
       "   'Document db• Web App API.',\n",
       "   'Experience in database designing, scalability, back -up and recovery, writing andoptimizing SQL code and Stored Procedures, creating functions, views, triggers and indexes.',\n",
       "   'End to end tracking Tool: Description: - This is real -time Tracking tool to track different business transactions like order, order response, functional acknowledgement, invoice flowing ins ide ICOE.',\n",
       "   'Worked Azure data lake store/analytics for big data processing',\n",
       "   'Microsoft Rewards members can earn points when searching with Bing, browsing with Microsoft Edge and making purchases at t he Xbox Store',\n",
       "   'Data warehouse: Data analysis, star/ snow flake schema data modeling and design specific todata warehousing and business intelligence environment.',\n",
       "   'End to end tracking tool stitches all the business transaction like order to cash flow and connects different hops inside ICOE like gateway, routing server, Proces sing server.',\n",
       "   'Rewards live dashboards gives a live picture of usage world -wide and by markets like US, Canada, Australia, new user regis tration count, top/bottom performing rewards offers, orders stats and weekly trends of user activities, orders and new user registrations.',\n",
       "   'Rewards data insights is data analytics',\n",
       "   'Stream analytics job to transform data Power'],\n",
       "  'skills': ['Analytics',\n",
       "   'Database',\n",
       "   'Data warehouse',\n",
       "   'Server',\n",
       "   'Web app',\n",
       "   'Business intelligence',\n",
       "   'Monitoring',\n",
       "   'Windows',\n",
       "   'Amp',\n",
       "   'Angular',\n",
       "   'Microsoft azure',\n",
       "   'Access control',\n",
       "   'Big data',\n",
       "   'Big data',\n",
       "   'Design',\n",
       "   'Business',\n",
       "   'Api',\n",
       "   'Schedule',\n",
       "   'Databases',\n",
       "   'Web app',\n",
       "   'Business intelligence',\n",
       "   'Azure',\n",
       "   'Data modeling',\n",
       "   'Server',\n",
       "   'Data analysis',\n",
       "   'Sql',\n",
       "   'Azure'],\n",
       "  'soft_skills': ['problem solving', 'Excellent analytical', 'communication'],\n",
       "  'languages': [],\n",
       "  'rating_details': {'educations': 0,\n",
       "   'gpa': 0,\n",
       "   'job_titles': 0,\n",
       "   'years_experiences': 0.5125,\n",
       "   'experiences': 0.38247787952423096,\n",
       "   'skills': 0.24,\n",
       "   'soft_skills': 0.5583804845809937,\n",
       "   'languages': 1},\n",
       "  'rating': 0.36539888942241666}]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_resume = rating_model.top_resume_by_rating()\n",
    "\n",
    "top_resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resume 1's Rating = 0.37, details:\n",
      "\n",
      " - Educations: 0.0000\n",
      " - Gpa: 0.0000\n",
      " - Job_titles: 0.0000\n",
      " - Years_experiences: 0.5125\n",
      " - Experiences: 0.3825\n",
      " - Skills: 0.2400\n",
      " - Soft_skills: 0.5584\n",
      " - Languages: 1.0000\n"
     ]
    }
   ],
   "source": [
    "for idx, resume in enumerate(resume_features):\n",
    "    \n",
    "    print(f\"\\nResume {idx + 1}'s Rating = {resume['rating']:.2f}, details:\\n\")\n",
    "    \n",
    "    for category, rating in resume['rating_details'].items():\n",
    "        \n",
    "        print(f' - {category.capitalize()}: {rating:.4f}')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SROOMARIZER",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
