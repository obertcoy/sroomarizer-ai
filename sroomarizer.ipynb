{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "__Gv83q-zXwm"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Lomba\\ITFEST\\SROOMARIZER\\ai\\SROOMARIZER\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From d:\\Lomba\\ITFEST\\SROOMARIZER\\ai\\SROOMARIZER\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from PyPDF2 import PdfReader\n",
        "from transformers import TFAutoModelForSeq2SeqLM, AutoTokenizer, BartForConditionalGeneration, TFT5ForConditionalGeneration, DataCollatorWithPadding, AutoModelForSeq2SeqLM\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA Available: False\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Check if CUDA is available\n",
        "cuda_available = torch.cuda.is_available()\n",
        "\n",
        "print(f\"CUDA Available: {cuda_available}\")\n",
        "\n",
        "# If CUDA is available, check the number of GPUs\n",
        "if cuda_available:\n",
        "    num_gpus = torch.cuda.device_count()\n",
        "    print(f\"Number of GPUs: {num_gpus}\")\n",
        "    for i in range(num_gpus):\n",
        "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "972PZYU9zwJh"
      },
      "outputs": [],
      "source": [
        "# Preprocess\n",
        "\n",
        "def clean_data(extracted_text):\n",
        "    extracted_text = ''.join(extracted_text.replace('\\n', ' '))\n",
        "    # extracted_text = [text.lower() for text in extracted_text]\n",
        "\n",
        "    return extracted_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6hZsaWWs0M4Y"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Lomba\\ITFEST\\SROOMARIZER\\SROOMARIZER\\lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ACER\\.cache\\huggingface\\hub\\models--facebook--bart-large-cnn. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n",
            "d:\\Lomba\\ITFEST\\SROOMARIZER\\SROOMARIZER\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "PRETRAINED_MODEL = 'facebook/bart-large-cnn'\n",
        "# PRETRAINED_MODEL = 'burberg92/resume_summary'\n",
        "\n",
        "\n",
        "model = BartForConditionalGeneration.from_pretrained(PRETRAINED_MODEL)\n",
        "tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kh2APkPRLMHf",
        "outputId": "3fd7e278-52f0-4a02-f054-520068908795"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading readme: 100%|██████████| 241/241 [00:00<00:00, 975B/s]\n",
            "Downloading data: 100%|██████████| 36.8k/36.8k [00:01<00:00, 31.3kB/s]\n",
            "Generating train split: 100%|██████████| 100/100 [00:00<00:00, 2432.43 examples/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['resume', 'ex_summary'],\n",
              "        num_rows: 80\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['resume', 'ex_summary'],\n",
              "        num_rows: 20\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "finetune_dataset = load_dataset(\"burberg92/resume_summary\")\n",
        "\n",
        "finetune_dataset = finetune_dataset['train'].train_test_split(test_size=0.2, seed=42)\n",
        "\n",
        "finetune_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "ab76eb13717b47f6b28abc9d8b2e20ba",
            "4b14e3bdcee14e02bcb21541d0f90142",
            "31e723aa8a2446ba905bfeac1d97aeba",
            "dbeb2b965dc6437f8ed1268c0bc431d0",
            "d726861db1e4484ca5cf88d9efbd734e",
            "e63aa564a7304ceb8a63fa6720704e29",
            "53bd68b95b3c4371b0948ae57356fddc",
            "03cd4ce4172145c6bb5fd0a72ecd3356",
            "18e483b54cef4bb29a5a94c252e66464",
            "91bed07d9f6c443ca370f03a541735d2",
            "76b19c4ba3e14de7b77e5e42812e9c55"
          ]
        },
        "id": "CyZmtIN3Tm_p",
        "outputId": "f5c29387-20cf-4e4a-fb14-cbfc7506251f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map:   0%|          | 0/80 [00:00<?, ? examples/s]d:\\Lomba\\ITFEST\\SROOMARIZER\\SROOMARIZER\\lib\\site-packages\\transformers\\tokenization_utils_base.py:4126: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "Map: 100%|██████████| 80/80 [00:00<00:00, 1440.36 examples/s]\n",
            "Map: 100%|██████████| 20/20 [00:00<00:00, 886.67 examples/s]\n"
          ]
        }
      ],
      "source": [
        "def preprocess_function(examples):\n",
        "    inputs = tokenizer(examples['resume'], max_length=512, truncation=True, padding=\"max_length\")\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(examples['ex_summary'], max_length=150, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return inputs\n",
        "\n",
        "train_dataset = finetune_dataset['train'].map(preprocess_function, batched=True)\n",
        "val_dataset = finetune_dataset['test'].map(preprocess_function, batched=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bOx1OpGhUrL6"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhUerxmCf9sN",
        "outputId": "eea6be8e-2cf7-44c6-e525-554c81c850bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['resume', 'ex_summary', 'input_ids', 'attention_mask', 'labels'],\n",
              "    num_rows: 80\n",
              "})"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZzJuQJkmfb-G"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from rouge import Rouge\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    print(predictions, labels)\n",
        "\n",
        "    rouge = Rouge()\n",
        "\n",
        "    scores = rouge.get_scores(predictions, labels)\n",
        "\n",
        "    return {\"scores\": scores}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xP_EWFfYbc7a"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "epochs = 5\n",
        "batch_size = 4\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=epochs,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "LfO1zJSSYrXD",
        "outputId": "22adc041-8dd5-47b1-87e9-b864b2a9cea7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 10/100 [03:32<30:41, 20.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 8.0872, 'grad_norm': 25.911968231201172, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.5}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 20/100 [08:20<36:14, 27.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 7.3558, 'grad_norm': 13.724514961242676, 'learning_rate': 2.0000000000000003e-06, 'epoch': 1.0}\n"
          ]
        }
      ],
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "7AJL-kVyksnn",
        "outputId": "e852db3f-9ba2-40a5-8604-53f2a0b132f7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Anthonio Obert Software Developer+62 81273724892 laisobert2@gmail.com  Jakarta, Indonesia SUMMARY A passionate college student with a keen interest in software development that is able to learn quickly and delve deeply into  new subjects. Currently working as a Database Administrator for Bina Nusantara's Software Laboratory, where I manage and  maintain student scores across multiple campuses with honesty and integrity. Capable of working under pressure and  meeting deadlines.  EXPERIENCE 02/2024 - Present Database Administrator  Bina Nusantara University  Manage and maintain student scores for laboratory subjects across six campuses: Kemanggisan, Alam Sutera, Bekasi,  Bandung, Malang, and Semarang.  Maintain web application to support internal and external activities.  Create and maintain SQL query for internal and external requests.  Provide student's scores data to identify and improve laboratory processes.  Schedule important dates for laboratory activities.  Post student's scores in Bina Nusantara University's internal application for students  Process assistant's honor payment for case making and correction.  02/2023 - 02/2024 Laboratory Assistant  Bina Nusantara University  Teach hands-on programming classes (C, SQL, R, Python, Java, HTML, CSS, JS, etc).  Created and graded student assignments, exams, and projects.  Created and Passed Game Development (Unity, C#) for assistant's self-development project.  Built a Desktop Application (Next.js, Electron, Typescript, Firebase, UML), Facebook Clone (React + Vite, Typescript, Go,  GraphQL, PostgreSQL), Android Mobile Application (Kotlin, Firebase) for assistant's self-development project.  EDUCATION 09/2022 - 09/2026 Computer Science  Bina Nusantara University - Bachelor's Degree  GPA: 3.82  IOFEST 2024 Web Development Finalist  SKILLS Excel Intermediate Java Intermediate Python IntermediateSQL Advanced CSS Advanced Typescript Advanced 1 / 2LANGUAGES English Intermediate Bahasa Native 2 / 2\""
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Read PDF\n",
        "\n",
        "PDF_PATH = '/Anthonio Obert - Software Developer - CV (1).pdf'\n",
        "\n",
        "reader = PdfReader(PDF_PATH)\n",
        "n_pages = len(reader.pages)\n",
        "\n",
        "extracted_text = ''\n",
        "\n",
        "for i in range(n_pages):\n",
        "    page = reader.pages[i]\n",
        "    extracted_text += page.extract_text()\n",
        "\n",
        "extracted_text = clean_data(extracted_text)\n",
        "extracted_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmFUH-Q-mMEg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAymB1-rv0E0",
        "outputId": "f2884b56-8ecb-4a90-9e20-43d7b9ee0177"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1976"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(extracted_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucGrQHWNjH9G",
        "outputId": "6930bb15-b930-423a-bfa6-aa3aa537c8a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\"Results-oriented Software Developer with expertise in C, SQL, R, Python, Java, HTML, CSS, and JS. Capable of working under pressure and meeting deadlines. Holds a Bachelor's Degree in Computer Science from Bina Nusantara University and is a Web Development Finalist with proficiency in Excel and other software tools. Phone number is 81273724892 and email address is laisobert2@gmail.com in Jakarta, Indonesia. If you are concerned about a security breach, call the National Suicide Prevention Lifeline at 1-800-273\"]"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\")\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "inputs = tokenizer([extracted_text], truncation=True, return_tensors='pt', max_length=512).to(device)\n",
        "\n",
        "summary_ids = model.generate(inputs['input_ids'], num_beams=4, early_stopping=True, min_length=100, max_length=120)\n",
        "summary = ([tokenizer.decode(id, skip_special_tokens=True, clean_up_tokenization_spaces=True) for id in summary_ids])\n",
        "\n",
        "summary"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03cd4ce4172145c6bb5fd0a72ecd3356": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18e483b54cef4bb29a5a94c252e66464": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "31e723aa8a2446ba905bfeac1d97aeba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03cd4ce4172145c6bb5fd0a72ecd3356",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_18e483b54cef4bb29a5a94c252e66464",
            "value": 20
          }
        },
        "4b14e3bdcee14e02bcb21541d0f90142": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e63aa564a7304ceb8a63fa6720704e29",
            "placeholder": "​",
            "style": "IPY_MODEL_53bd68b95b3c4371b0948ae57356fddc",
            "value": "Map: 100%"
          }
        },
        "53bd68b95b3c4371b0948ae57356fddc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76b19c4ba3e14de7b77e5e42812e9c55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91bed07d9f6c443ca370f03a541735d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab76eb13717b47f6b28abc9d8b2e20ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4b14e3bdcee14e02bcb21541d0f90142",
              "IPY_MODEL_31e723aa8a2446ba905bfeac1d97aeba",
              "IPY_MODEL_dbeb2b965dc6437f8ed1268c0bc431d0"
            ],
            "layout": "IPY_MODEL_d726861db1e4484ca5cf88d9efbd734e"
          }
        },
        "d726861db1e4484ca5cf88d9efbd734e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbeb2b965dc6437f8ed1268c0bc431d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91bed07d9f6c443ca370f03a541735d2",
            "placeholder": "​",
            "style": "IPY_MODEL_76b19c4ba3e14de7b77e5e42812e9c55",
            "value": " 20/20 [00:00&lt;00:00, 151.50 examples/s]"
          }
        },
        "e63aa564a7304ceb8a63fa6720704e29": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
