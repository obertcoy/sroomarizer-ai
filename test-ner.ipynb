{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Lomba\\ITFEST\\SROOMARIZER\\ai\\SROOMARIZER\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "d:\\Lomba\\ITFEST\\SROOMARIZER\\ai\\SROOMARIZER\\lib\\site-packages\\transformers\\utils\\generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "d:\\Lomba\\ITFEST\\SROOMARIZER\\ai\\SROOMARIZER\\lib\\site-packages\\transformers\\utils\\generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import random\n",
    "from PyPDF2 import PdfReader\n",
    "import pandas as pd\n",
    "\n",
    "from spacy.pipeline import EntityRuler\n",
    "from spacy.lang.en import English\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jsonlines\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from typing import List\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturesExtractor:\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.nlp = spacy.load('./data/train_model/model_ner/')\n",
    "        \n",
    "        if \"sentencizer\" not in self.nlp.pipe_names:\n",
    "            self.nlp.add_pipe(\"sentencizer\")\n",
    "        \n",
    "        if 'entity_ruler' not in self.nlp.pipe_names:\n",
    "            ruler = self.nlp.add_pipe('entity_ruler', after='ner')\n",
    "            ruler.from_disk(constants.SKILLS_PATTERN_PATH)\n",
    "            \n",
    "            job_title_patterns = pd.read_csv(constants.JOB_TITLE_PATH)['Job Title'].unique()\n",
    "            \n",
    "            for title in job_title_patterns:\n",
    "                ruler.add_patterns([{\"label\": \"JOB TITLE\", \"pattern\": title}])\n",
    "        \n",
    "        self._CATEGORIES_PATTERN = constants.CATEGORIES_PATTERN\n",
    "    \n",
    "    def fit_transform(self, input: List[str]):\n",
    "        \n",
    "        self._text_arr = []\n",
    "        self._feature_arr = []\n",
    "        self._input_len = len(input)\n",
    "\n",
    "        for i in range(self._input_len):\n",
    "            \n",
    "            doc = self._remove_excess_spaces(input[i])\n",
    "            self._text_arr.append(doc)\n",
    "\n",
    "            self._extract_features(doc)\n",
    "\n",
    "        return self._text_arr, self._feature_arr\n",
    "\n",
    "    def _remove_excess_spaces(self, text):\n",
    "            \n",
    "        doc = self.nlp(re.sub(r'\\s+', ' ', text).strip())\n",
    "\n",
    "        return doc\n",
    "            \n",
    "\n",
    "    def _extract_features(self, doc):\n",
    "\n",
    "        feature_dict = {\n",
    "\n",
    "            'name': self._extract_name(doc),\n",
    "            'phone': self._extract_phone(doc),\n",
    "            'educations': self._extract_educations(doc),\n",
    "            'gpa': self._extract_gpa(doc),\n",
    "            'job_titles' : self._extract_job_titles(doc),\n",
    "            'years_experiences': self._extract_years_experiences(doc),\n",
    "            'experiences': self._extract_experiences(doc),\n",
    "            'skills': self._extract_skills(doc),\n",
    "            'soft_skills': self._extract_soft_skills(doc),\n",
    "            'languages': self._extract_languages(doc),\n",
    "            \n",
    "        }\n",
    "        \n",
    "        self._feature_arr.append(feature_dict)\n",
    "           \n",
    "\n",
    "    \n",
    "    def _extract_name(self, doc):\n",
    "        \n",
    "        name = []\n",
    "\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == 'PERSON':\n",
    "                name.append(ent.text)\n",
    "\n",
    "        return name\n",
    "\n",
    "\n",
    "    def _extract_phone(self, doc):\n",
    "\n",
    "        pattern = r'(?:\\+?(?:\\d{1,3}[-.\\s]?)?(?:\\(?\\d{2,4}\\)?[-.\\s]?)?(?:\\d{2,4}[-.\\s]?){2,5}\\d{2,4})'\n",
    "\n",
    "        matches = re.findall(pattern, doc.text)\n",
    "\n",
    "        return matches\n",
    "    \n",
    "    def _extract_educations(self, doc):\n",
    "        \n",
    "        educations = []\n",
    "\n",
    "        pattern = self._CATEGORIES_PATTERN['EDUCATIONS']\n",
    "        \n",
    "        matches = re.findall(pattern, doc.text)\n",
    "        for match in matches:\n",
    "            educations.append(match.strip())\n",
    "            \n",
    "        for ent in doc.ents:\n",
    "            if 'DIPLOMA' in ent.label_:\n",
    "                educations.append(ent.text)\n",
    "\n",
    "        return [edu for edu in set(educations)]\n",
    "    \n",
    "    def _extract_gpa(self, doc):\n",
    "        \n",
    "        gpas = []\n",
    "        \n",
    "        for ent in doc.ents:\n",
    "            if 'GPA' in ent.label_:\n",
    "                gpas.append(ent.text)\n",
    "                \n",
    "        return [gpa.capitalize() for gpa in set(gpas)]\n",
    "    \n",
    "    def _extract_job_titles(self, doc):\n",
    "        \n",
    "        job_titles = []\n",
    "        \n",
    "        for ent in doc.ents:\n",
    "            if 'JOB TITLE' in ent.label_:\n",
    "                job_titles.append(ent.text)\n",
    "        \n",
    "        return [job for job in set(job_titles)]\n",
    "    \n",
    "    def _extract_years_experiences(self, doc):\n",
    "        \n",
    "        years_experiences= []\n",
    "        \n",
    "        pattern = self._CATEGORIES_PATTERN['YEARS_EXPERIENCES']\n",
    "        \n",
    "        sentences = [sent.text.strip() for sent in doc.sents]\n",
    "\n",
    "        # for sentence in sentences:\n",
    "        #     if re.search(pattern, sentence, re.IGNORECASE):\n",
    "        #         years_experiences_sentences.append(sentence)\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            \n",
    "            matches = re.findall(pattern, sentence, re.IGNORECASE)\n",
    "                        \n",
    "            for match in matches:\n",
    "                \n",
    "                # Prevent context not parsed\n",
    "                try:\n",
    "\n",
    "                    \n",
    "                    year = match  # Extracted years\n",
    "                    year = re.sub(r'\\+', '', year)  # Remove '+' if present\n",
    "\n",
    "                    try:\n",
    "                        \n",
    "                        year = int(year)\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        \n",
    "                        print(f\"Error converting {match} to number: {e}\")\n",
    "                        continue\n",
    "\n",
    "                    match_doc = self.nlp(sentence)\n",
    "                    \n",
    "                    skills = self._extract_skills(match_doc)\n",
    "                    job_titles = self._extract_job_titles(match_doc)\n",
    "                    languages = self._extract_languages(match_doc)\n",
    "                    \n",
    "                    keywords = skills + job_titles + languages\n",
    "\n",
    "\n",
    "                    years_experience_dict = {\n",
    "                        'text': sentence,\n",
    "                        'year': year,\n",
    "                        'keywords': keywords\n",
    "                    }\n",
    "                    \n",
    "                    years_experiences.append(years_experience_dict)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing match {match}: {e}\")\n",
    "                    continue \n",
    "            \n",
    "        return years_experiences\n",
    "    \n",
    "    def _extract_experiences(self, doc):\n",
    "        \n",
    "        experiences = []\n",
    "        \n",
    "        pattern = self._CATEGORIES_PATTERN['EXPERIENCES']\n",
    "        \n",
    "        sentences = [sent.text.strip() for sent in doc.sents]\n",
    "\n",
    "        for sentence in sentences:\n",
    "            if re.search(pattern, sentence, re.IGNORECASE):\n",
    "                experiences.append(sentence)\n",
    "                \n",
    "        for ent in doc.ents:\n",
    "            if 'EXPERIENCE' in ent.label_:\n",
    "                experiences.append(ent.text)\n",
    "        \n",
    "        return [exp for exp in set(experiences)]\n",
    "    \n",
    "    def _extract_skills(self, doc):\n",
    "\n",
    "        skills = []\n",
    "\n",
    "        for ent in doc.ents:\n",
    "            if 'SKILL' in ent.label_ and 'SOFT SKILL' not in ent.label_:\n",
    "                skills.append(ent.text)\n",
    "                \n",
    "        return [skill.capitalize() for skill in set(skills)]\n",
    "    \n",
    "    def _extract_soft_skills(self, doc):\n",
    "        \n",
    "        soft_skills = []\n",
    "        \n",
    "        for ent in doc.ents:\n",
    "            if 'SOFT SKILL' in ent.label_:\n",
    "                soft_skills.append(ent.text)\n",
    "                \n",
    "        return [soft_skill for soft_skill in set(soft_skills)]\n",
    "\n",
    "    def _extract_languages(self, doc):\n",
    "        \n",
    "        languages = []\n",
    "\n",
    "        for ent in doc.ents:\n",
    "            if 'LANGUAGE' in ent.label_:\n",
    "                languages.append(ent.text)\n",
    "                \n",
    "        return [language.capitalize() for language in set(languages)]\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_parse(text):\n",
    "    \n",
    "    model = spacy.load('en_core_web_trf')\n",
    "    \n",
    "    print(model.pipe_names)\n",
    "\n",
    "    doc = model(text)\n",
    "    for ent in doc.ents:\n",
    "        print(f'{ent.label_.upper():{30}}- {ent.text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Educations:\n",
      "Bachelor's degree in Computer Science or equivalent\n",
      "\n",
      "GPA:\n",
      "  - No GPA information found\n",
      "\n",
      "Job Titles:\n",
      "Software Engineer\n",
      "\n",
      "Years Experience:\n",
      "{'text': 'Having minimum 3 years of experience in software engineering (Java), application development or system development + experience in RDBMS and NoSQL databases.', 'year': 3, 'keywords': ['Databases', 'Software engineering', 'Java', 'Nosql']}\n",
      "\n",
      "Experiences:\n",
      "Participate in the service support as on-call Participate and contribute to innovation and problem-solving Post student's scores in Bina Nusantara University's internal application for students Process assistant's honor payment for case making Schedule important dates for laboratory activities.\n",
      "Experience in version control (Git/SVN/Mercurial) and familiarity with development collaboration tools\n",
      "As a Backend Software Engineer, you are expected to: Be responsible for designing, building, improving, or maintaining our backend applications, third-party data integration, data API, backend systems, or working with monitoring tools and infrastructure Work in cross-functional teams and meet great people regularly from top tier technology, consulting, product, or academic background Be encouraged to speak your mind, propose ideas, influence others, and continuously grow yourself Participate and contribute to engineering hygiene such as code review, unit testing, and integration testing Participate and contribute to the solution and architectural design review.\n",
      "Good business acumen, excellent problem skills and broad understanding of software and system design.\n",
      "Schedule important dates for laboratory activities. ‎ Requirements Bachelor's degree in Computer Science or equivalent from a reputable university with good academic results is preferred.\n",
      "Comfortable working up and down the technology stack.\n",
      "Traveloka services related to new products, business models, business growth, market expansion and process optimization.\n",
      "Strong object-oriented analysis and design skills.\n",
      "\n",
      "Skills:\n",
      "Api\n",
      "Bitbucket\n",
      "Teamcity\n",
      "Nosql\n",
      "Github\n",
      "Ansible\n",
      "Java\n",
      "Design\n",
      "Business\n",
      "Testing\n",
      "Phabricator\n",
      "Kubernetes\n",
      "Software engineering\n",
      "Support\n",
      "Databases\n",
      "Monitoring tools\n",
      "Travis ci\n",
      "Data integration\n",
      "Software\n",
      "Engineering\n",
      "Azure\n",
      "System integration\n",
      "Jenkins\n",
      "Business process\n",
      "Code review\n",
      "\n",
      "Skills:\n",
      "effective, reliable and scalable solutions\n",
      "excellent problem skills\n",
      "innovation\n",
      "problem-solving\n",
      "\n",
      "Languages:\n"
     ]
    }
   ],
   "source": [
    "PDF_PATH = './PDF/Anthonio Obert - Software Developer - CV (1).pdf'\n",
    "\n",
    "reader = PdfReader(PDF_PATH)\n",
    "n_pages = len(reader.pages)\n",
    "\n",
    "extracted_text = ''\n",
    "\n",
    "for i in range(n_pages):\n",
    "    page = reader.pages[i]\n",
    "    extracted_text += page.extract_text()\n",
    "\n",
    "extractor = FeaturesExtractor()\n",
    "\n",
    "texts, features = extractor.fit_transform([extracted_text])\n",
    "job_text, job_features = extractor.fit_transform([constants.DUMMY_JOB_DESCRIPTION])\n",
    "\n",
    "print(f'\\nEducations:')\n",
    "for education in job_features[0]['educations']:\n",
    "    print(education)\n",
    "    \n",
    "print(f'\\nGPA:')\n",
    "gpa = job_features[0]['gpa']\n",
    "if gpa:\n",
    "    for g in gpa:\n",
    "        print(f'  - {g}')\n",
    "else:\n",
    "    print('  - No GPA information found')\n",
    "\n",
    "print(f'\\nJob Titles:')\n",
    "for job_title in job_features[0]['job_titles']:\n",
    "    print(job_title)\n",
    "    \n",
    "print(f'\\nYears Experience:')\n",
    "for years_experience in job_features[0]['years_experiences']:\n",
    "    print(years_experience)\n",
    "\n",
    "print(f'\\nExperiences:')\n",
    "for experience in job_features[0]['experiences']:\n",
    "    print(experience)\n",
    "    \n",
    "print(f'\\nSkills:')\n",
    "for skill in job_features[0]['skills']:\n",
    "    print(skill)   \n",
    "    \n",
    "print(f'\\nSkills:')\n",
    "for soft_skill in job_features[0]['soft_skills']:\n",
    "    print(soft_skill)   \n",
    "    \n",
    "print(f'\\nLanguages:')\n",
    "for language in job_features[0]['languages']:\n",
    "    print(language)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Name:\n",
      "  - No name found\n",
      "\n",
      "Phone:\n",
      "  - +62 81273724892\n",
      "\n",
      "Educations:\n",
      "  - Bachelor's Degree GPA\n",
      "  - Bachelor's Degree GPA:\n",
      "\n",
      "GPA:\n",
      "  - 3.82\n",
      "\n",
      "Job Titles:\n",
      "  - Database Administrator\n",
      "\n",
      "Years Experience:\n",
      "  - No years experience found\n",
      "\n",
      "Experiences:\n",
      "  - Maintain web application to support internal and external activities.\n",
      "  - Schedule important dates for laboratory activities.\n",
      "  - EXPERIENCE 02/2024 - Present Database Administrator Bina Nusantara University Manage and maintain student scores for laboratory subjects across six campuses: Kemanggisan, Alam Sutera, Bekasi, Bandung, Malang, and Semarang.\n",
      "  - Currently working as a Database Administrator for Bina Nusantara's Software Laboratory, where I manage and maintain student scores across multiple campuses with honesty and integrity.\n",
      "  - Create and maintain SQL query for internal and external requests.\n",
      "  - Provide student's scores data to identify and improve laboratory processes.\n",
      "  - Post student's scores in Bina Nusantara University's internal application for students Process assistant's honor payment for case making\n",
      "  - Built a Desktop Application (Next.js, Electron, Typescript, Firebase, UML), Facebook Clone (React + Vite, Typescript, Go, GraphQL, PostgreSQL), Android Mobile Application (Kotlin, Firebase) for assistant's self-development project.\n",
      "\n",
      "Skills:\n",
      "  - Unity\n",
      "  - Computer science\n",
      "  - Css\n",
      "  - Software\n",
      "  - Typescript\n",
      "  - Game development\n",
      "  - C\n",
      "  - Java\n",
      "  - Python\n",
      "  - Software\n",
      "  - Support\n",
      "\n",
      "Soft Skills:\n",
      "  - Capable of working under pressure\n",
      "\n",
      "Languages:\n",
      "  - No languages found\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print all extracted features in a formatted way\n",
    "print(f'\\nName:')\n",
    "name = features[0]['name']\n",
    "if name:\n",
    "    print(f'  - {name[0]}')  # Assuming there is only one name\n",
    "else:\n",
    "    print('  - No name found')\n",
    "\n",
    "print(f'\\nPhone:')\n",
    "phone = features[0]['phone']\n",
    "if phone:\n",
    "    for p in phone:\n",
    "        print(f'  - {p}')\n",
    "else:\n",
    "    print('  - No phone number found')\n",
    "\n",
    "print(f'\\nEducations:')\n",
    "education = features[0]['educations']\n",
    "if education:\n",
    "    for edu in education:\n",
    "        print(f'  - {edu}')\n",
    "else:\n",
    "    print('  - No education information found')\n",
    "\n",
    "print(f'\\nGPA:')\n",
    "gpa = features[0]['gpa']\n",
    "if gpa:\n",
    "    for g in gpa:\n",
    "        print(f'  - {g}')\n",
    "else:\n",
    "    print('  - No GPA information found')\n",
    "    \n",
    "print(f'\\nJob Titles:')\n",
    "job_titles = features[0]['job_titles']\n",
    "if job_titles:\n",
    "    for job in job_titles:\n",
    "        print(f'  - {job}')\n",
    "else:\n",
    "    print('  - No job titles found')\n",
    "    \n",
    "    \n",
    "print(f'\\nYears Experience:')\n",
    "years_experiences = features[0]['years_experiences']\n",
    "if years_experiences:\n",
    "    for years in years_experiences:\n",
    "        print(f'  - {years}')\n",
    "else:\n",
    "    print('  - No years experience found')\n",
    "\n",
    "print(f'\\nExperiences:')\n",
    "experience = features[0]['experiences']\n",
    "if experience:\n",
    "    for exp in experience:\n",
    "        print(f'  - {exp}')\n",
    "else:\n",
    "    print('  - No experience information found')\n",
    "\n",
    "print(f'\\nSkills:')\n",
    "skills = features[0]['skills']\n",
    "if skills:\n",
    "    for skill in skills:\n",
    "        print(f'  - {skill}')\n",
    "else:\n",
    "    print('  - No skills found')\n",
    "\n",
    "print(f'\\nSoft Skills:')\n",
    "soft_skills = features[0]['soft_skills']\n",
    "if soft_skills:\n",
    "    for s_skill in soft_skills:\n",
    "        print(f'  - {s_skill}')\n",
    "else:\n",
    "    print('  - No soft skills found')\n",
    "\n",
    "print(f'\\nLanguages:')\n",
    "languages = features[0]['languages']\n",
    "if languages:\n",
    "    for language in languages:\n",
    "        print(f'  - {language}')\n",
    "else:\n",
    "    print('  - No languages found')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m resume_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mencode(features\u001b[38;5;241m.\u001b[39mfeature_arr[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexperiences\u001b[39m\u001b[38;5;124m'\u001b[39m], convert_to_tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m job_description_embedding \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(job_features\u001b[38;5;241m.\u001b[39mfeature_arr[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexperiences\u001b[39m\u001b[38;5;124m'\u001b[39m], convert_to_tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "resume_embeddings = model.encode(features.feature_arr[0]['experiences'], convert_to_tensor=True)\n",
    "job_description_embedding = model.encode(job_features.feature_arr[0]['experiences'], convert_to_tensor=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume score: 0.25\n"
     ]
    }
   ],
   "source": [
    "similarity = util.pytorch_cos_sim(resume_embeddings, job_description_embedding)\n",
    "\n",
    "# Aggregate similarities (e.g., average)\n",
    "score = similarity.mean().item()\n",
    "print(f\"Resume score: {score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResumeRater:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self._pretrained_model = SentenceTransformer(constants.PRETRAINED_SENTENCE_TRANSFORMERS_MODEL)\n",
    "        \n",
    "        self._RATING_WEIGHTS = constants.RATING_WEIGHTS\n",
    "            \n",
    "    def fit_transform(self, job_description_text: List[str], resume_text: List[dict]):\n",
    "        \n",
    "        self._extractor = FeaturesExtractor()\n",
    "        \n",
    "        job_text, job_features = extractor.fit_transform(job_description_text)\n",
    "\n",
    "        # Only 1 job posting description\n",
    "        self._job_text = job_text[0] \n",
    "        self._job_features = job_features[0]\n",
    "        \n",
    "        self._resume_text, self._resume_features = extractor.fit_transform(resume_text)\n",
    "        \n",
    "        for feature in self._resume_features:\n",
    "        \n",
    "            feature['rating_details'] = {\n",
    "                \n",
    "                'educations': self._rate_educations(feature['educations']),\n",
    "                'gpa': self._rate_gpa(feature['gpa']),\n",
    "                'job_titles' : self._rate_job_titles(feature['job_titles']),\n",
    "                # 'years_experiences': self._rate_years_experiences(feature['years_experience']), TO BE UPDATED\n",
    "                'years_experiences': 0,\n",
    "                'experiences': self._rate_experiences(feature['experiences']),\n",
    "                'skills': self._rate_skills(feature['skills']),\n",
    "                'soft_skills': self._rate_soft_skills(feature['soft_skills']),\n",
    "                'languages': self._rate_languages(feature['languages']),\n",
    "                \n",
    "            }\n",
    "            \n",
    "            final_rating = 0\n",
    "            \n",
    "            for category, rating in feature['rating_details'].items():\n",
    "                \n",
    "                try:\n",
    "                    \n",
    "                    calculated_rating =  rating * self._RATING_WEIGHTS[str(category).upper()]\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    \n",
    "                    print(f'Error on parsing rating weights: {e}')\n",
    "                    continue\n",
    "                \n",
    "                final_rating += calculated_rating\n",
    "                 \n",
    "            feature['rating'] = final_rating\n",
    "            \n",
    "        \n",
    "        return self._resume_text, self._resume_features\n",
    "    \n",
    "    def _calculate_cosine_similarity_matrix_mean(self, job_feature_category: List[str], resume_feature_category: List[str], use_threshold= False, threshold= 0.42):\n",
    "        \n",
    "        job_embeddings = self._pretrained_model.encode(job_feature_category)\n",
    "        resume_embeddings  = self._pretrained_model.encode(resume_feature_category)\n",
    "        \n",
    "        cosine_sim_matrix = util.pytorch_cos_sim(job_embeddings, resume_embeddings).numpy()\n",
    "        \n",
    "        top_similarity = cosine_sim_matrix.max(axis= 1) # Rows: Job, Columns: Resume -> Get max similarity per job\n",
    "        \n",
    "        score = top_similarity.mean()\n",
    "        \n",
    "        if use_threshold:\n",
    "\n",
    "            matches = np.sum(top_similarity >= threshold)\n",
    "                \n",
    "            # Calculate the score based on the number of matches and similarity >= threshold\n",
    "            if matches > 0:\n",
    "                score = (matches / len(job_text)) * np.mean(top_similarity[top_similarity >= threshold])\n",
    "            else:\n",
    "                score = 0.0\n",
    "                        \n",
    "        return score\n",
    "\n",
    "    def _calculate_matching_words_score(self, job_word_list: List[str], resume_word_list: List[str]):\n",
    "        \n",
    "        n_job_word = len(job_word_list)\n",
    "        \n",
    "        if n_job_word <= 0:\n",
    "            return 1 # No extracted word on the category\n",
    "        \n",
    "        job_word_list = [word.lower() for word in job_word_list]\n",
    "        resume_word_list = [word.lower() for word in resume_word_list]\n",
    "        \n",
    "        score = 0\n",
    "        \n",
    "        for resume_word in resume_word_list:\n",
    "            \n",
    "            if resume_word in job_word_list:\n",
    "                score += 1\n",
    "\n",
    "        score /= n_job_word\n",
    "        \n",
    "        return score\n",
    "        \n",
    "    \n",
    "    def _rate_educations(self, resume_feature: List[str]):\n",
    "        \n",
    "        return self._calculate_cosine_similarity_matrix_mean(self._job_features['educations'], resume_feature)\n",
    "    \n",
    "    def _rate_gpa(self, resume_feature: List[str]):\n",
    "        \n",
    "        return 0\n",
    "    \n",
    "    def _rate_job_titles(self, resume_feature: List[str]):\n",
    "        \n",
    "        return self._calculate_cosine_similarity_matrix_mean(self._job_features['job_titles'], resume_feature, use_threshold=True)\n",
    "    \n",
    "    def _rate_years_experiences(self, resume_feature: List[str]):\n",
    "        \n",
    "        return self._calculate_cosine_similarity_matrix_mean(self._job_features['educations'], resume_feature)\n",
    "    \n",
    "    def _rate_experiences(self, resume_feature: List[str]):\n",
    "        \n",
    "        return self._calculate_cosine_similarity_matrix_mean(self._job_features['experiences'], resume_feature)\n",
    "        \n",
    "    def _rate_skills(self, resume_feature: List[str]):\n",
    "        \n",
    "        return self._calculate_matching_words_score(self._job_features['skills'], resume_feature)\n",
    "        \n",
    "    def _rate_soft_skills(self, resume_feature: List[str]):\n",
    "        \n",
    "        return self._calculate_cosine_similarity_matrix_mean(self._job_features['soft_skills'], resume_feature)\n",
    "        \n",
    "    def _rate_languages(self, resume_feature: List[str]):\n",
    "        \n",
    "        return self._calculate_matching_words_score(self._job_features['languages'], resume_feature)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Lomba\\ITFEST\\SROOMARIZER\\ai\\SROOMARIZER\\lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_resume_features = [\n",
    "    \n",
    "    {\n",
    "        'year' : 5,\n",
    "        'keywords': ['Java', 'Nosql', 'Databases', 'Software engineering']\n",
    "    },\n",
    "    {\n",
    "        'year' : 3,\n",
    "        'keywords': ['Typescript', 'Web Developer', 'Javascript']\n",
    "    },\n",
    "    \n",
    "]\n",
    "\n",
    "test_job_features = [\n",
    "    {\n",
    "        'year': 4,\n",
    "        'keywords': ['Java', 'Software engineering', 'Web Development', 'Databases']\n",
    "    },\n",
    "    {\n",
    "        'year': 2,\n",
    "        'keywords': ['Python', 'Data Science', 'Machine Learning', 'Analytics']\n",
    "    },\n",
    "    {\n",
    "        'year': 5,\n",
    "        'keywords': ['JavaScript', 'Frontend Development', 'React', 'UI/UX Design']\n",
    "    },\n",
    "    {\n",
    "        'year': 3,\n",
    "        'keywords': ['C++', 'Embedded Systems', 'Firmware', 'IoT']\n",
    "    }\n",
    "]\n",
    "\n",
    "def _calculate_cosine_similarity_matrix_mean(job_feature_category: List[str], resume_feature_category: List[str]):\n",
    "        \n",
    "    job_embeddings = model.encode(job_feature_category)\n",
    "    resume_embeddings  = model.encode(resume_feature_category)\n",
    "    \n",
    "    cosine_sim_matrix = util.pytorch_cos_sim(job_embeddings, resume_embeddings).numpy()\n",
    "    \n",
    "    top_similarity = cosine_sim_matrix.max(axis= 1) # Because job is in rows\n",
    "    \n",
    "    return top_similarity.mean(), top_similarity\n",
    "\n",
    "def _calculate_year_weight(job_year, resume_year):\n",
    "    \n",
    "    weight = min(job_year / resume_year, 1)\n",
    "    \n",
    "    return weight\n",
    "\n",
    "for item in\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3267703  0.5252687  0.32776105 0.4130693  0.32009926]\n",
      " [0.39474565 0.3680032  0.29165304 0.32076508 0.30375063]\n",
      " [0.28090385 0.3277973  0.30289125 0.30853605 0.2963429 ]\n",
      " [0.66312987 0.4990375  0.45114562 0.35039157 0.30742115]]\n",
      "\n",
      "[0.5252687  0.39474565 0.3277973  0.66312987]\n",
      "\n",
      "0.47773534\n",
      "Resume score: 0.2971\n"
     ]
    }
   ],
   "source": [
    "job_text = ['Marketing Manager', 'Social Media Specialist', 'Content Creator', 'Software Engineer']\n",
    "resume_text = ['Mechanical Engineer', 'Project Manager', 'CAD Designer', 'Manufacturing Supervisor', 'Database Administrator']\n",
    "\n",
    "job = model.encode(job_text)\n",
    "resume = model.encode(resume_text)\n",
    "\n",
    "cosine_sim = util.pytorch_cos_sim(job, resume)\n",
    "\n",
    "job_len = len(job)\n",
    "\n",
    "cosine_sim_matrix = cosine_sim.numpy()\n",
    "print(cosine_sim_matrix)\n",
    "\n",
    "max_per_job = cosine_sim_matrix.max(axis=1)\n",
    "\n",
    "print()\n",
    "print(max_per_job)\n",
    "\n",
    "print()\n",
    "print(max_per_job.mean())\n",
    "\n",
    "threshold = 0.4\n",
    "\n",
    "matches = np.sum(max_per_job >= threshold)\n",
    "    \n",
    "# Calculate the score based on the number of matches and their strengths\n",
    "if matches > 0:\n",
    "    score = (matches / len(job_text)) * np.mean(max_per_job[max_per_job >= threshold])\n",
    "else:\n",
    "    score = 0.0\n",
    "    \n",
    "print(f\"Resume score: {score:.4f}\")\n",
    "\n",
    "\n",
    "# rating = 0\n",
    "\n",
    "# if resume.lower() in job.lower():\n",
    "#     rating += 0.1\n",
    "    \n",
    "# print(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levenshtein Distance: 20\n",
      "Levenshtein Similarity Percentage: 45.95%\n"
     ]
    }
   ],
   "source": [
    "import Levenshtein\n",
    "\n",
    "# Define resume and job description\n",
    "resume = \"Bachelor's Degree\"\n",
    "job = \"Bachelor's degree in Computer Science\"\n",
    "\n",
    "# Compute Levenshtein distance\n",
    "levenshtein_distance = Levenshtein.distance(resume.lower(), job.lower())\n",
    "\n",
    "print(f\"Levenshtein Distance: {levenshtein_distance}\")\n",
    "\n",
    "# Compute similarity percentage (optional)\n",
    "max_len = max(len(resume), len(job))\n",
    "similarity_percentage = (1 - levenshtein_distance / max_len) * 100\n",
    "print(f\"Levenshtein Similarity Percentage: {similarity_percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Lomba\\ITFEST\\SROOMARIZER\\ai\\SROOMARIZER\\lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken using model.similarity: 0.04840564727783203\n",
      "Time taken using manual encoding + util.pytorch_cos_sim: 0.038173675537109375\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Load pre-trained model\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Define texts\n",
    "texts = [\n",
    "    \"Bachelor's Degree GPA\",\n",
    "    \"Bachelor's Degree GPAaaaaaaaaaaaaaaaaaaaa:\"\n",
    "]\n",
    "job_descriptions = [\n",
    "    \"Bachelor's degree in Computer Science or equivalent from a reputable university with good academic results is preferred\",\n",
    "    \"Bachelor's degree in Computer Science\"\n",
    "]\n",
    "\n",
    "# Benchmark model.similarity (if available)\n",
    "start_time = time.time()\n",
    "similarity_scores = model.similarity(model.encode(job_descriptions), model.encode(texts))  # Hypothetical function\n",
    "end_time = time.time()\n",
    "print(\"Time taken using model.similarity:\", end_time - start_time)\n",
    "\n",
    "# Benchmark manual encoding + util.pytorch_cos_sim\n",
    "start_time = time.time()\n",
    "resume_embeddings = model.encode(texts, convert_to_numpy=True)\n",
    "job_embeddings = model.encode(job_descriptions, convert_to_numpy=True)\n",
    "cosine_sim = util.pytorch_cos_sim(job_embeddings, resume_embeddings)\n",
    "end_time = time.time()\n",
    "print(\"Time taken using manual encoding + util.pytorch_cos_sim:\", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test', 'test2', 'test3', 'test4']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1 = ['test', 'test2']\n",
    "list2 = ['test3']\n",
    "list3 = ['test4']\n",
    "\n",
    "final_list = list1 + list2 + list3\n",
    "\n",
    "final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Lomba\\ITFEST\\SROOMARIZER\\ai\\SROOMARIZER\\lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rating_model = ResumeRater()\n",
    "\n",
    "resume_text, resume_features = rating_model.fit_transform([constants.DUMMY_JOB_DESCRIPTION], [extracted_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resume 1's Rating = 0.30, details:\n",
      "\n",
      " - Educations: 0.6003\n",
      " - Gpa: 0.0000\n",
      " - Job_titles: 0.0000\n",
      " - Years_experiences: 0.0000\n",
      " - Experiences: 0.4563\n",
      " - Skills: 0.1600\n",
      " - Soft_skills: 0.1866\n",
      " - Languages: 1.0000\n"
     ]
    }
   ],
   "source": [
    "for idx, resume in enumerate(resume_features):\n",
    "    \n",
    "    print(f\"\\nResume {idx + 1}'s Rating = {resume['rating']:.2f}, details:\\n\")\n",
    "    \n",
    "    for category, rating in resume['rating_details'].items():\n",
    "        \n",
    "        print(f' - {category.capitalize()}: {rating:.4f}')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SROOMARIZER",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
